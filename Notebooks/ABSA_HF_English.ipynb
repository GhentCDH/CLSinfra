{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPF-UNLgrn2V"
      },
      "outputs": [],
      "source": [
        "#Task: ABSA\n",
        "#Language: English\n",
        "#Contact: Pranaydeep Singh <pranaydeep.singh@ugent.be>\n",
        "#Last Update: 2024-05-13\n",
        "#Requirements: flair, transformers, ipymarkup\n",
        "#Encoding: UTF-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKp8tagern2X"
      },
      "source": [
        "# Aspect-Based Sentiment Analysis (ABSA) with FLAIR for CLS\n",
        "\n",
        "This Notebook shows you how to perform ABSA, which consists of two sub-tasks.\n",
        "- Task A: Extraction of **Aspects** from unlabelled text\n",
        "- Task B: Finding the sentiment associated with each **Aspect**.\n",
        "\n",
        "**Aspects** can be any entities of interest in the text for which we want to find out the associated sentiment. This mostly depends on the kind of data you are working on. For example, the **Aspects** in a news corpora might be person names and organizations, while **Aspects** in a dataset of restaurant reviews might be names of dishes and drinks.\n",
        "\n",
        "For this reason, we recommend training your own AE (Task A: Aspect Extraction) system using this notebook as a guide. If you do not have any unlabelled data, you can also used the created model directly as shown in Section 2, however this will only work well if the data and therefore the **Aspects** are similar to the ones we have used here. The sample dataset used here mostly includes named entities, especially Flora and Fauna annotated as aspects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRfXHyvPrn2a"
      },
      "source": [
        "❗ To understand and adapt this Notebook for your own use case, we expect a basic understanding of these concepts:\n",
        "\n",
        "- The task of ABSA\n",
        "- Fine-tuning\n",
        "- Language Models\n",
        "- Python and frequently used libraries (HuggingFace Transformers, FLAIR, scikit-learn, etc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x6NrY4Hrn2b"
      },
      "source": [
        "#### Installing the Dependencies\n",
        "\n",
        "We will first install all the libraries needed to run this notebook, this might take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9dMvHrHrn2b",
        "outputId": "b3d4f57b-504d-412d-f1ce-6efa72bf9722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: flair in /usr/local/lib/python3.9/site-packages (0.11.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (4.30.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (1.10.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (3.8.2)\n",
            "Requirement already satisfied: ipymarkup in /usr/local/lib/python3.9/site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (1.0.2)\n",
            "Collecting statistics\n",
            "  Downloading statistics-1.0.3.5.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.9/site-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.9/site-packages (from flair) (3.8.3)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.9/site-packages (from flair) (4.62.3)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.9/site-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.9/site-packages (from flair) (0.3)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.9/site-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.9/site-packages (from flair) (1.2.12)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.9/site-packages (from flair) (0.2.7)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.9/site-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/site-packages (from flair) (2023.3.23)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.9/site-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/site-packages (from flair) (4.9.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/site-packages (from flair) (6.0.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.9/site-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/site-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.9/site-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.9/site-packages (from flair) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/site-packages (from flair) (0.15.1)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.9/site-packages (from flair) (4.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/site-packages (from flair) (8.12.0)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.9/site-packages (from flair) (0.5.4)\n",
            "Requirement already satisfied: pptree in /usr/local/lib/python3.9/site-packages (from flair) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from gdown==4.4.0->flair) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/site-packages (from gdown==4.4.0->flair) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/site-packages (from gdown==4.4.0->flair) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/artemis/Library/Python/3.9/lib/python/site-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/artemis/Library/Python/3.9/lib/python/site-packages (from pandas) (2021.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/site-packages (from matplotlib) (8.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (5.4.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.9/site-packages (from ipymarkup) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (2.1.0)\n",
            "Collecting docutils>=0.3 (from statistics)\n",
            "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/site-packages (from gensim>=3.4.0->flair) (6.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/site-packages (from huggingface-hub->flair) (2021.11.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.6.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (0.18.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.5.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.9/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.9/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (1.26.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (2020.12.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.2.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: statistics\n",
            "  Building wheel for statistics (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for statistics: filename=statistics-1.0.3.5-py3-none-any.whl size=7436 sha256=4c0ad7ac0ca6048a1ffd2059fee57d41e697e9bb9693c7717bc0bf73180b7c64\n",
            "  Stored in directory: /Users/artemis/Library/Caches/pip/wheels/26/3c/70/9467407f3aa90862061eadcd286627b23a8bab6789b667776f\n",
            "Successfully built statistics\n",
            "Installing collected packages: docutils, statistics\n",
            "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed docutils-0.21.2 statistics-1.0.3.5\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install flair transformers torch pandas matplotlib ipymarkup scikit-learn statistics tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4hQpY_Hrn2c"
      },
      "source": [
        "## Section 1: Fine-tuning a Model with your annotated dataset\n",
        "\n",
        "In this section, we will cover how you can fine-tune models for the task of ABSA from scratch using a few tools like transformers, the FLAIR-NLP toolkit, etc.\n",
        "If you do not have access to annotated data for ABSA and therefore want to directly use the trained model we have created, then head to Section 2.\n",
        "As detailed above, ABSA consists of two tasks Aspect Extraction (Task A) and Sentiment Classification (Task B), let's look into Task A first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjFSoh0Drn2c"
      },
      "source": [
        "### Task A: Aspect Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFVSE4lBrn2c"
      },
      "source": [
        "The first and hardest task of ABSA, involves finding interesting aspects in unstructured text. The aspects can be a single word or a large phrase or named entity. This makes the task more difficult since there is no standard word length or limits for the aspects.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXfPn63_rn2c"
      },
      "source": [
        "#### A.1 Loading and checking your Data\n",
        "\n",
        "Now we will load our annotated dataset and do some quick checks to see how it looks. We have fine-tuned on our sample dataset. To train on your data, replace the paths of the files with your personal created dataset. However, make sure it's in the same format or you  might run into issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx6ehdCfrn2c",
        "outputId": "f321e2a8-e58e-4a04-f3aa-fae2bc44dbd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Author</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Weber</td>\n",
              "      <td>B-ASPECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>I-ASPECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Max</td>\n",
              "      <td>I-ASPECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Token     Label\n",
              "0  Author         O\n",
              "1   Weber  B-ASPECT\n",
              "2       ,  I-ASPECT\n",
              "3     Max  I-ASPECT\n",
              "4       ,         O"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('english_aspect_extraction.txt', sep='\\t', header=None, names=['Token', 'Label'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hqBp6vkrn2d"
      },
      "source": [
        "Let's also split our data into a training, validation and test parts while we are at it.\n",
        "\n",
        "We first make a 80:20 split, and keep 80 percent of the data for training the model.\n",
        "\n",
        "From the 20 percent we wil divide it in half, and use 10 percent for validation and 10 percent for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5CZfRFurn2d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
        "val_df, test_df = train_test_split(val_test_df, test_size=0.5, shuffle=False)\n",
        "\n",
        "train_df.to_csv('train.txt', sep='\\t', header=False, index=False)\n",
        "val_df.to_csv('val.txt', sep='\\t', header=False, index=False)\n",
        "test_df.to_csv('test.txt', sep='\\t', header=False, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yXz6Cggrn2d"
      },
      "source": [
        "As you can see, we have successfully loaded our data. The **token** column refers to the current token in question, the **Label** column refers to the label of the current token. There are 3 labels:\n",
        "\n",
        "- **B-ASPECT**: A token that marks the beginning of an aspect\n",
        "- **I-ASPECT**: A token that is inside an aspect\n",
        "- **O**: A token that is not part of any aspect\n",
        "\n",
        "This data format is called the IOB (Inside, Outside, Beginning) format, and this is how most aspect extraction datasets are stored.\n",
        "\n",
        "If your data is in another format, please refer to the [notebook on data conversion](https://teams.microsoft.com/l/message/19:32c7ccd6-db3e-49e0-ba27-87ec6aa57819_5a8f8965-f480-4f16-bb21-4d0b35a6246b@unq.gbl.spaces/1715587586609?context=%7B%22contextType%22%3A%22chat%22%7D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5pABsEorn2e"
      },
      "source": [
        "#### A.2 Sequence Tagger with Flair-NLP: Loading Modules, Data & Defining Parameters\n",
        "\n",
        "[Flair-NLP](https://github.com/flairNLP/flair) is a widely used toolkit for training advanced sequence tagger models for various applications like Named Entity Recognition, Aspect Based Sentiment Analysis, etc. The library provides a variety of options to train your models like word embeddings, pre-trained transformers, conditional random fields (CRFs), etc. Please refer to the [documentation of FLAIR](https://flairnlp.github.io/docs) for a more detailed overview of it's capabilities.\n",
        "\n",
        "In this particular example, we will use one of the options available in FLAIR to train our own Sequence Tagger using a pre-trained Transformer model.\n",
        "\n",
        "Let's begin by loading the necessary modules of Flair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leU9e_77rn2e"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.data import Sentence\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G26733LCrn2e"
      },
      "source": [
        "Now let's begin by loading out data into Flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7BzU5b8rn2e",
        "outputId": "33d2bfbf-2cb1-4a1b-ec0a-98f7ac6d46ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-13 15:56:01,544 Reading data from .\n",
            "2024-05-13 15:56:01,545 Train: train.txt\n",
            "2024-05-13 15:56:01,546 Dev: val.txt\n",
            "2024-05-13 15:56:01,547 Test: test.txt\n"
          ]
        }
      ],
      "source": [
        "columns = {0: 'text', 1: 'label'} # This specifies which column is the text and which column is the label. In our case, the text is in the first column and the label is in the second column.\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(\"./\", columns,\n",
        "                              train_file='train.txt',\n",
        "                              dev_file='val.txt',\n",
        "                              test_file='test.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3-TG3H7rn2f"
      },
      "source": [
        "Now let's define a few variables for our training. These are some key parameters so some additional information about them is added in the comments. Be sure to read them so you can make appropriate choices for your setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP_2Dsc_rn2f"
      },
      "outputs": [],
      "source": [
        "model_name = 'emanjavacas/MacBERTh' #This is the pre-trained model we are going to use. You can change this to any other model from the transformers library. To look for available models, you can visit https://huggingface.co/models\n",
        "fine_tune = False #If you want to fine-tune the model, set this to True. If you want to use the model as it is, set this to False. Fine-tuning results in better performance but requires more computational resources and time.\n",
        "hidden_size = 256 #This is the size of the hidden layer of the model. You can change this to any other value depending on the computational resources you have. If your training is taking too long, experiment with reducing this number.\n",
        "use_crf = False #If you want to use a CRF layer on top of the model, set this to True. This is recommended for sequence labeling tasks like NER. If you set this to False, the model will use a softmax layer for classification.\n",
        "output_model_path = 'en_aspect_extraction_model' #This is the path where the trained model will be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxWlWsf4rn2g"
      },
      "source": [
        "#### A.3 Sequence Tagger with Flair-NLP: Final Setup & Training\n",
        "\n",
        "Perfect, now let's setup all the parameters and details of our model to-be trained soon!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8aGMnQNrn2g",
        "outputId": "f91e1527-1753-47f0-fce3-da388a7ff8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-13 16:10:01,514 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-13 16:10:02,055 Dictionary created for label 'label' with 3 values: ASPECT (seen 227097 times), nan (seen 22709 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary with 3 tags: <unk>, ASPECT, nan\n",
            "2024-05-13 16:10:04,505 SequenceTagger predicts: Dictionary with 9 tags: O, S-ASPECT, B-ASPECT, E-ASPECT, I-ASPECT, S-nan, B-nan, E-nan, I-nan\n"
          ]
        }
      ],
      "source": [
        "# 1. which column do we want to predict?\n",
        "label_type = 'label'\n",
        "\n",
        "# 3. make the label dictionary from the corpus, i.e. a mapping of labels to numbers\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type, )\n",
        "print(label_dict)\n",
        "\n",
        "# 4. initialize fine-tuneable transformer embeddings WITH document context. These are the embeddings that will be used for classifying the tokens into aspects.\n",
        "embeddings = TransformerWordEmbeddings(model = model_name,\n",
        "                                       layers=\"-1\", #ONLY USE THE LAST LAYER (common practice, but can experiment with other layers)\n",
        "                                       subtoken_pooling=\"first\",\n",
        "                                       fine_tune= fine_tune,\n",
        "                                       use_context=True, #document context is considered during the embedding process (surrounding words, ...)\n",
        "                                       )\n",
        "\n",
        "# 5. initialize our sequence tagger, you can experiment with the hyperparameters here to suit your needs. Some tinkering might help you reach better performance for your dataset.\n",
        "tagger = SequenceTagger(hidden_size=hidden_size,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type='bio',\n",
        "                        use_crf=use_crf,\n",
        "                        use_rnn=False,\n",
        "                        reproject_embeddings=False,\n",
        "                        )\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCKjNMXrn2g"
      },
      "source": [
        "Great, everything seems to be ready, it's time to start training. Remember, this can take quite a while, so grab yourself a cup of coffee in the meantime!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiQVIwi8rn2g"
      },
      "outputs": [],
      "source": [
        "trainer.fine_tune(output_model_path,\n",
        "                  learning_rate=5.0e-6, # Can be tuned for your data\n",
        "                  mini_batch_size=4, # Should be adjusted based on your computation resources. If the code crashes due to memory errors, reduce it. If you have a big GPU, you can increase it to speed up training.\n",
        "                  mini_batch_chunk_size=1,  # remove this parameter to speed up computation if you have a big GPU\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVUm95n9rn2g"
      },
      "source": [
        "#### A.4 Testing the Model\n",
        "\n",
        "\n",
        "Our model is ready, want to test it on a random sentence? Let's do it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lybkgpOJrn2g",
        "outputId": "68f102f9-04d5-4473-fcef-e23d4f691b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"I saw a weeping willow while passing down the alleyway . The thorns of the roses reminded me of home , in Alabama .\" → [\"I\"/ASPECT, \"saw\"/nan, \"a\"/nan, \"weeping\"/nan, \"willow\"/nan, \"while\"/nan, \"passing\"/nan, \"down\"/nan, \"the\"/nan, \"alleyway\"/nan, \".\"/nan, \"The\"/nan, \"thorns\"/nan, \"of\"/nan, \"the\"/nan, \"roses\"/nan, \"reminded\"/nan, \"me\"/nan, \"of\"/nan, \"home\"/nan, \",\"/nan, \"in\"/ASPECT, \"Alabama\"/ASPECT, \".\"/ASPECT]\n"
          ]
        }
      ],
      "source": [
        "sentence = Sentence('I saw a weeping willow while passing down the alleyway. The thorns of the roses reminded me of home, in Alabama.')\n",
        "\n",
        "# predict aspect tags\n",
        "tagger.predict(sentence)\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMKxV4KArn2h"
      },
      "source": [
        "As, you can see, even with some conservative settings we are able to have a pretty good aspect extraction model!\n",
        "\n",
        "To make this model even better, you can try setting **fine_tune** to **True**, increasing the **hidden_size** and setting **use_crf** to True.\n",
        "\n",
        "You can also further tune the hyper-parameters such as **learning_rate** since the optimal values can vary significantly depending on the model and data.\n",
        "\n",
        "If you want to use this model to extract aspects from a large file, you can check out Section 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he6ynL8Srn2h"
      },
      "source": [
        "### Task B: Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5jhalvdrn2i"
      },
      "source": [
        "Since our model for Task A is capable of identifying interesting aspects in a sentence, we can move on to training a system for the next task of ABSA, ie. Sentiment Classification.\n",
        "In this task we want to associate a sentiment label (eg: Positive, Negative, Neutral) to each aspect found by our model from Task A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksZ6e4mGrn2i"
      },
      "source": [
        "#### B.1 Loading and checking your Data\n",
        "\n",
        "Once more, we will begin by first loading our data. The format of this file will look different than the previous file. This time we also need sentiment information for the aspects.\n",
        "Our sample dataset for stored in the Comma-seperated Values (CSV) format. Your data might look different so make sure to adapt this code for your data format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWOf-xSmrn2i",
        "outputId": "8e36f8ec-d52d-4fa4-af09-25a72feadb10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect</th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>category</th>\n",
              "      <th>sentiment_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breeze</td>\n",
              "      <td>In the P.M. had a moderate breeze at East , wh...</td>\n",
              "      <td>ASPECT</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cloudy weather</td>\n",
              "      <td>At Midnight the wind came to South-South-West ...</td>\n",
              "      <td>ASPECT</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gale</td>\n",
              "      <td>Cloudy weather ; Winds at South-West and South...</td>\n",
              "      <td>ASPECT</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gale</td>\n",
              "      <td>Had a steady brisk Gale at South-South-West wi...</td>\n",
              "      <td>ASPECT</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gales</td>\n",
              "      <td>Fresh Gales at South , which in the A.M. veer ...</td>\n",
              "      <td>ASPECT</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           aspect                                         sentence_1 category  \\\n",
              "0          breeze  In the P.M. had a moderate breeze at East , wh...   ASPECT   \n",
              "1  Cloudy weather  At Midnight the wind came to South-South-West ...   ASPECT   \n",
              "2            Gale  Cloudy weather ; Winds at South-West and South...   ASPECT   \n",
              "3            Gale  Had a steady brisk Gale at South-South-West wi...   ASPECT   \n",
              "4           Gales  Fresh Gales at South , which in the A.M. veer ...   ASPECT   \n",
              "\n",
              "   sentiment_cat  \n",
              "0            3.0  \n",
              "1            4.0  \n",
              "2            4.0  \n",
              "3            4.0  \n",
              "4            4.0  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data/English_asp_null_sent.csv')\n",
        "\n",
        "df.rename(columns = {\"text\": \"aspect\", \"_sentence_text\": \"sentence_1\", \"annotation\": \"category\"}, inplace = True) # We will rename the columns to make them more readable\n",
        "df.drop(['Unnamed: 0', 'source_file', 'sentence', 'begin', 'end', 'annotator',     # We will drop the columns that are not needed\n",
        "       '_annotation', 'aspect_cat'], axis=1, inplace=True)\n",
        "\n",
        "df.dropna(inplace=True) # Remove rows with missing values\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8QkQLcrn2j"
      },
      "source": [
        "As you can see, the data format looks quite different this time. We have the full text in the **sentence_1** column. The aspect is stored in the **aspect** column. While the sentiment label we will use is in the **sentiment_cat** column. The sentiment labels follow the standard range from 1 to 5, 5 being extremely positive and 1 being extremely negative.\n",
        "\n",
        "Lastly, now we will convert the data to a simpler format, ie. lists for easier processing in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bgXwy8-rn2j"
      },
      "outputs": [],
      "source": [
        "sentence_list = list(df[\"sentence_1\"])\n",
        "aspect_list = list(df[\"aspect\"])\n",
        "tag_list = list(df[\"sentiment_cat\"])\n",
        "\n",
        "raw_data = [[sent, asp, tag] for sent, asp, tag in zip(sentence_list, aspect_list, tag_list)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZNms_d8rn2k"
      },
      "source": [
        "#### B.2 Load model & create tagset\n",
        "\n",
        "First let's define a few variables and load the model we will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYBT2xtzrn2k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_name = 'emanjavacas/MacBERTh' #This is the pre-trained model we are going to use. You can change this to any other model from the transformers library. To look for available models, you can visit https://huggingface.co/models\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # This will automatically use the GPU if it is available, otherwise it will use the CPU.\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN8n1ncfrn2k"
      },
      "source": [
        "We need to assign a number to each sentiment label so the model can interpret it. In Task A this was done using the **corpus.make_label_dictionary** functionality, but that only works when using flair. For this Task, we will be using **transformers**, so we will have to find another way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hfmzPRTrn2k",
        "outputId": "72c4f4f1-1bf4-4f28-b175-cbcf8a711b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0}\n"
          ]
        }
      ],
      "source": [
        "tags = list(set(df[\"sentiment_cat\"]))\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
        "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
        "print(idx2tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82fF-_EJrn2l"
      },
      "source": [
        "#### B.3 Helper functions for manipulating data\n",
        "\n",
        "Now we need to change the format of the data a bit. This is necessary because transformers break down words into smaller units called sub-words. This might cause some confusion, since an aspect like \"John Oliver\" annotated as sentiment **4.0**, might be broken down into 4 parts for example, \"Jo\", \"hn\", \"Oli\", \"ver\". In that case we also need to adjust our data so we can assign the sentiment label **4.0** to all those 4 parts. To know more about how tokenization in transformers works and the technical details around it please take a look at [this guide](https://docs.mistral.ai/guides/tokenization/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXLEWR0nrn2l"
      },
      "outputs": [],
      "source": [
        "#This functions finds the index position of the aspect term in the sentence\n",
        "\n",
        "def get_pos(sent_list,aspect_list):\n",
        "    first_pos = sent_list.index(aspect_list[1]) #first position bc [0] is always the CLS token in transformers\n",
        "    final_pos = []\n",
        "    for i in range(0,len(aspect_list)-2):\n",
        "        final_pos.append(first_pos+i)\n",
        "    return final_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2HnhBItrn2l"
      },
      "outputs": [],
      "source": [
        "#This class will construct a Torch dataset from the tagged sentences. Each instance in the dataset will contain the words, their position in the sentence and tags for those words.\n",
        "\n",
        "from torch.utils import data\n",
        "class ABSADataset(data.Dataset):\n",
        "    def __init__(self, tagged_sents):\n",
        "        sents, aspects, tags = [], [], [] # list of lists\n",
        "        bugged = 0\n",
        "        for sent in tagged_sents:\n",
        "            try:\n",
        "                sent_tokens = tokenizer.encode(sent[0])\n",
        "                aspect_tokens = tokenizer.encode(sent[1])\n",
        "                pos_aspects = get_pos(sent_tokens, aspect_tokens)\n",
        "                tag = sent[2]\n",
        "                sents.append(sent_tokens)\n",
        "                aspects.append(pos_aspects)\n",
        "                tags.append(tag)\n",
        "            except:\n",
        "                bugged+=1\n",
        "        print(\"Ignoring {} Buggy Annotations\".format(bugged))\n",
        "        self.sents, self.aspects, self.tags = sents, aspects, tags\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, aspects, tags = self.sents[idx], self.aspects[idx], tag2idx[self.tags[idx]] # words, tags: string list\n",
        "        return words, aspects, tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpBJ4cOxrn2l"
      },
      "source": [
        "#### B.4 Creating our Model for extracting embeddings\n",
        "\n",
        "Let's wrap our loaded model in a class and then get embeddings for each aspect from the transformer. We will then use these embeddings to classify the sentiment of the aspect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTl21lvXrn2l"
      },
      "outputs": [],
      "source": [
        "#This class defines a network where we pass full sentences to a transformer for the entire context but only store the embeddings for the aspect terms.\n",
        "#This is done by using the position index of the aspect term in the sentence we stored using our previous functions.\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
        "\n",
        "    def forward(self, sent, aspects, y):\n",
        "        '''\n",
        "        x: (N, T). int64\n",
        "        y: (N, T). int64\n",
        "        '''\n",
        "        sent = torch.LongTensor(sent).to(self.device)\n",
        "        aspects = torch.LongTensor(aspects).to(self.device)\n",
        "        y = torch.LongTensor(y).to(self.device)\n",
        "        input_ids = sent.unsqueeze(0)  # Batch size 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids)\n",
        "            last_hidden_states = outputs.last_hidden_state[0]  # Get last hidden state (embeddings)\n",
        "            start = 0\n",
        "            end = len(last_hidden_states)-1\n",
        "            context_window = 5 # define context window we're interested in (5 before and 5 after)\n",
        "\n",
        "            if aspects[0]-context_window>0:\n",
        "                start = aspects[0]-context_window\n",
        "            if aspects[-1]+context_window<len(last_hidden_states)-1:\n",
        "                end = aspects[-1]+context_window\n",
        "\n",
        "            all_aspects = []\n",
        "            for i in range(start,end):\n",
        "                all_aspects.append(i)\n",
        "\n",
        "            #For each index in all_aspects, it assigns the corresponding BERT embedding from the last_hidden_states tensor to the corresponding row in the bert_embeds tensor.\n",
        "            #Each row of bert_embeds now holds the BERT embedding for the corresponding aspect.\n",
        "\n",
        "            bert_embeds = torch.zeros(len(all_aspects),768).to(self.device)\n",
        "            for i, aspect in enumerate(all_aspects):\n",
        "                bert_embeds[i] = last_hidden_states[aspect]\n",
        "\n",
        "            #  calculates the mean of the embeddings along axis 0 (the rows).\n",
        "            #  This is done to obtain a single aggregated BERT embedding that represents the information from the context window around the aspects.\n",
        "\n",
        "            embedding = torch.mean(bert_embeds, axis=0).to(self.device)\n",
        "\n",
        "        return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95MfcniErn2m"
      },
      "outputs": [],
      "source": [
        "#This function will run our network from the previous cell on our entire dataset, therefore extracting and storing embeddings for each aspect term.\n",
        "\n",
        "def extract(model, iterator):\n",
        "    model.eval()\n",
        "\n",
        "    Words, Aspects, Y, Y_hat = [], [], [], [],\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            words, aspects, y = batch\n",
        "\n",
        "            _, _, y_hat, _ = model(words, aspects, y)  # y_hat: (N, T) = predicted labels\n",
        "            print(y_hat)\n",
        "\n",
        "            Words.extend(words)\n",
        "            Aspects.extend(aspects)\n",
        "            Y.extend(y.numpy().tolist())\n",
        "            Y_hat.extend([y_hat.cpu().numpy().tolist()])\n",
        "\n",
        "    ## calc metric\n",
        "    print(classification_report(Y, Y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umuo6_aErn2m"
      },
      "source": [
        "#### B.4 Initialising the Model & exctracting the embeddings\n",
        "\n",
        "Now we can begin to use all the massive functions we have defined in the previous sections and initialize first, our dataset, and then our model to be used for extracting the embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aovPLGCrn2n",
        "outputId": "f40ec2cc-50d8-4e97-f95f-382006294ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignoring 0 Buggy Annotations\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "dataset = ABSADataset(raw_data)\n",
        "data_iterator = data.DataLoader(dataset=dataset,\n",
        "                             batch_size=1,\n",
        "                             shuffle=False,\n",
        "                             num_workers=0,\n",
        "                             pin_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE-Z9oBrn2n"
      },
      "source": [
        "Perfect! Now let's initalize our network for extracting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVed6mU6rn2n",
        "outputId": "c8f8fd5c-477f-40ce-c2b4-91c68106bb52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Net()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF_ITDlCrn2n"
      },
      "source": [
        "Great, now let's run this model on our entire data to extract embeddings for all the aspects. Again, remember that this can take quite a while, so take a break!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joAcollern2n",
        "outputId": "658366f3-38ff-4d33-cad3-60e2d662e865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1322it [03:42,  5.94it/s]\n"
          ]
        }
      ],
      "source": [
        "embeddings = []\n",
        "import tqdm\n",
        "for i, batch in tqdm.tqdm(enumerate(data_iterator)):\n",
        "        words, aspects, y = batch\n",
        "        embedding = model(words, aspects, y)\n",
        "        embedding = embedding.cpu().numpy()\n",
        "        y = int(y.cpu().numpy()[0])\n",
        "        embeddings.append([embedding, y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHi2eU7grn2n"
      },
      "source": [
        "#### B.5 Setting up a Machine Learning Classifier\n",
        "\n",
        "Now that our embeddings are extracted. We can train a simple ML classifier to detect sentiment for an embedding. Let's first construct our data in the X (embeddings) and Y (labels) format of sklearn and then split it into a train and test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrT8fOSGrn2o"
      },
      "outputs": [],
      "source": [
        "X = [x[0] for x in embeddings]\n",
        "Y = [x[1] for x in embeddings]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF27v9S4rn2o"
      },
      "source": [
        "Let's see what a X and Y look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm-ECBg9rn2o",
        "outputId": "667237f2-c132-45a4-e849-a40cec2a7a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "___________ Sample Embedding ___________ \n",
            "[ 8.20019469e-02 -1.47756776e-02  1.80196762e-01 -2.00758934e-01\n",
            "  1.67954147e-01  5.63581944e-01 -3.01245362e-01  6.27293885e-01\n",
            "  5.68736494e-01  1.96950197e-01 -5.03707789e-02  2.73313731e-01\n",
            " -1.32441416e-01 -1.81252480e-01 -5.35731912e-02  6.91305771e-02\n",
            "  3.07307214e-01 -2.91986674e-01 -2.40733370e-01  3.92571956e-01\n",
            " -3.12691987e-01  9.61914510e-02 -1.14218239e-02  9.69716115e-04\n",
            "  2.52802908e-01 -3.00708041e-02 -1.75336644e-01 -9.14047565e-03\n",
            "  9.66977105e-02 -2.63373200e-02 -7.78606683e-02 -4.13104564e-01\n",
            " -1.50799185e-01  2.37354815e-01  3.91122729e-01 -2.59514928e-01\n",
            "  3.26071084e-01  4.80993152e-01  3.50112617e-01  2.79841349e-02\n",
            "  1.29022524e-01  7.90598541e-02  1.14769243e-01 -8.28820318e-02\n",
            " -4.21301186e-01 -2.27922589e-01  4.93911877e-02  3.11286021e-02\n",
            " -3.88510883e-01 -9.67323482e-02  5.47236800e-02 -1.18108466e-01\n",
            "  7.88913965e-01  3.49447690e-02 -9.44073200e-02  1.70284018e-01\n",
            " -7.92331919e-02 -1.20594176e-02  3.56431007e-01 -2.04093874e-01\n",
            "  1.04380064e-01  3.12680721e-01  1.86229706e-01  3.21257472e-01\n",
            " -1.09482214e-01 -4.47925925e-01 -1.69692233e-01  4.74555284e-01\n",
            " -1.42982081e-01 -1.22977402e-02  5.88976920e-01  6.76735342e-01\n",
            "  1.56842887e-01  8.54167938e-02 -3.68559927e-01 -1.28611758e-01\n",
            "  1.22311875e-01  2.22703546e-01  3.45604382e-02 -6.21748447e-01\n",
            "  2.02460468e-01 -2.39325985e-02 -6.12930655e-01  1.69840436e-02\n",
            " -4.72307205e-02 -4.15342987e-01 -3.05554092e-01 -6.94001168e-02\n",
            "  5.01866974e-02 -1.99828848e-01 -6.30188957e-02 -4.24532682e-01\n",
            " -6.77336380e-02  3.59557033e-01 -3.88948083e-01 -4.75769043e-02\n",
            "  1.45081773e-01  1.84668362e-01  1.72695033e-02  1.57832861e-01\n",
            "  3.27984065e-01  1.15696676e-01 -4.05033022e-01 -6.10919995e-03\n",
            "  3.08916092e-01 -4.86336797e-02  2.32170932e-02  4.12843674e-02\n",
            " -3.06639761e-01  6.73092306e-02  1.18660927e-01  1.77495442e-02\n",
            " -1.80002213e-01  9.22477245e-02  4.29644175e-02  1.68343693e-01\n",
            "  2.89391160e-01 -3.18695813e-01 -8.46298188e-02  3.35021839e-02\n",
            "  2.47254506e-01  7.10018948e-02  2.97504216e-01  7.63926804e-02\n",
            " -1.56460941e-01 -2.09639311e-01 -1.11533359e-01 -1.33313993e-02\n",
            "  2.20208943e-01 -4.65207398e-01  4.71794158e-01 -8.34747255e-02\n",
            "  1.35835633e-01 -3.00489306e-01 -3.24864648e-02  1.50007397e-01\n",
            "  4.00710613e-01 -3.14274102e-01 -2.92882502e-01 -3.09676766e-01\n",
            "  2.34428778e-01 -2.68192679e-01  3.74880910e-01  6.33099228e-02\n",
            " -3.37177664e-02 -1.61092773e-01  4.40139808e-02  3.54199111e-01\n",
            " -8.05460513e-02  3.33700150e-01  1.09224193e-01 -2.65073091e-01\n",
            "  7.55402803e-01 -5.22483476e-02 -1.27235472e-01  4.31888849e-02\n",
            "  2.92114764e-01 -7.30132908e-02  2.25326046e-01  3.72051269e-01\n",
            "  6.30517378e-02  1.48251414e-01  1.52865082e-01 -1.60034791e-01\n",
            "  1.79270789e-01 -1.58246607e-01  1.06908090e-01  8.69992673e-02\n",
            "  1.75048724e-01 -5.56102812e-01 -3.50062817e-01 -7.26434663e-02\n",
            "  4.44827646e-01 -6.40449107e-01 -4.57835883e-01  5.74548580e-02\n",
            "  4.76325899e-02 -1.84244439e-01  2.93915719e-01 -1.06055610e-01\n",
            "  3.16507131e-01  1.10168479e-01  2.73877531e-01  1.55423865e-01\n",
            " -3.07697922e-01  2.81715337e-02  5.02344131e-01 -6.11788258e-02\n",
            "  2.31512696e-01  7.97466040e-02 -2.96814650e-01  3.82662505e-01\n",
            "  1.22720428e-01 -3.18115860e-01 -9.11773145e-02 -4.06348795e-01\n",
            "  1.58984691e-01 -3.20482180e-02  2.65989691e-01 -8.58278200e-03\n",
            "  3.13183337e-01  2.04095230e-01  2.69045860e-01  1.37374863e-01\n",
            " -6.76958123e-03 -2.46452942e-01 -1.16212077e-01  6.84269220e-02\n",
            "  5.99380285e-02  3.23648721e-01  1.80826560e-01 -4.94119041e-02\n",
            "  6.27920106e-02 -5.61565906e-02  2.01535574e-03 -6.55182526e-02\n",
            "  9.96522233e-02  2.28266373e-01  1.20077379e-01 -2.79151320e-01\n",
            "  3.52132916e-01  2.56599098e-01 -2.99434662e-01 -7.58873224e-02\n",
            " -1.88859954e-01  2.29668140e-01  1.96761653e-01 -1.50891811e-01\n",
            "  1.80181071e-01 -5.28075360e-02 -4.47022095e-02  2.23483935e-01\n",
            " -4.92593288e-01  1.77436069e-01 -3.30195278e-01 -4.31055665e-01\n",
            " -2.92040288e-01  3.06514293e-01 -5.50244935e-02  2.81043738e-01\n",
            "  1.28056452e-01  1.73688531e-02  1.31863937e-01 -9.62238014e-02\n",
            "  3.28478105e-02  3.67125958e-01  3.17894220e-02 -5.41071177e-01\n",
            "  3.43045235e-01 -2.52364516e-01  1.18072778e-01 -9.90110561e-02\n",
            " -1.13740057e-01 -2.53799856e-01 -9.59938206e-03 -1.65743887e-01\n",
            "  1.08250596e-01  1.47685423e-01 -3.27978700e-01  1.21050097e-01\n",
            "  2.29505554e-01  9.30400789e-02  6.59332797e-02 -8.18135858e-01\n",
            " -2.82001227e-01 -2.99480379e-01 -3.00648957e-01 -1.08597612e+00\n",
            " -2.67306641e-02  1.90011173e-01 -2.46821027e-02  9.26788270e-01\n",
            " -4.45752032e-02 -2.50978827e-01  3.41956653e-02 -1.32291481e-01\n",
            " -2.21130550e-01 -5.46532422e-02 -5.74055195e-01  2.58155465e-01\n",
            "  4.67021763e-01 -4.51823711e-01  5.15782945e-02 -2.03473344e-01\n",
            " -3.94623369e-01  6.79589957e-02 -1.16537651e-02 -2.56684780e-01\n",
            " -3.72629851e-01 -2.07470402e-01 -1.28696382e-01  1.25769094e-01\n",
            " -3.68730724e-01 -2.51771420e-01 -3.98451596e-01  5.78221828e-02\n",
            "  1.38627768e-01 -3.15808624e-01  2.76354760e-01  2.30113268e-01\n",
            " -1.71873316e-01 -1.88323364e-01  2.60303497e-01 -2.97755122e-01\n",
            "  1.69361174e-01  2.14453921e-01 -9.21757445e-02 -2.48785317e-01\n",
            " -5.94330877e-02 -4.17708792e-03  1.86588749e-01 -2.52748877e-01\n",
            " -3.30098659e-01  4.85797703e-01 -2.46372893e-01  3.16745549e-01\n",
            " -1.73972383e-01 -2.20477059e-01  2.39732176e-01  3.22118253e-01\n",
            " -2.74474770e-01 -1.61531910e-01  1.58447072e-01 -8.31660032e-01\n",
            "  4.24237639e-01 -4.68683466e-02  3.06291282e-01  4.90416661e-02\n",
            "  3.99264514e-01  3.94979455e-02 -5.51968753e-01 -9.24828723e-02\n",
            " -1.30379096e-01 -2.66237438e-01  2.05212101e-01  1.31710544e-01\n",
            "  5.32943569e-02  2.83967406e-01  1.45434543e-01 -1.32048026e-01\n",
            " -3.19903642e-01  1.02750473e-02 -2.83053249e-01 -1.89504009e-02\n",
            " -2.98385531e-01  1.78582221e-01 -1.82852939e-01 -2.93896317e-01\n",
            " -6.61333621e-01 -3.38149935e-01  5.93037844e-01  1.70778930e-02\n",
            "  3.81763726e-01  6.08948469e-01  2.32920423e-02  2.92413801e-01\n",
            " -2.40493402e-01 -7.89295137e-02  3.66268665e-01  2.76773218e-02\n",
            "  5.99944115e-01 -2.42664531e-01 -3.27888906e-01  6.23158691e-03\n",
            " -2.01555431e-01 -4.05269712e-01 -1.01988651e-01  2.36814395e-02\n",
            " -1.08854510e-01  1.46144137e-01 -2.99851131e-02  3.75564009e-01\n",
            "  3.56625944e-01 -9.49847400e-02  4.30041671e-01  2.82895595e-01\n",
            " -2.87657797e-01 -1.87555790e-01 -9.72007513e-02 -4.71279144e-01\n",
            "  1.04346678e-01  2.01217026e-01  2.20191091e-01 -3.08386922e-01\n",
            "  4.92595702e-01  2.09331319e-01 -1.94905907e-01 -1.58255070e-01\n",
            " -5.56891024e-01  1.12368584e-01 -2.83506345e-02  1.63278162e-01\n",
            "  2.90659338e-01  1.37210354e-01  4.91171926e-01  3.04361016e-01\n",
            " -3.61317754e-01  1.22792192e-01 -2.41563261e-01  4.29422893e-02\n",
            " -3.38535666e-01 -6.84776096e-05 -2.41639704e-01  2.01827064e-02\n",
            " -1.16189077e-01 -7.78315291e-02 -3.88972551e-01 -2.86854178e-01\n",
            "  1.94322810e-01  1.17950685e-01  2.25888029e-01  3.77096653e-01\n",
            " -2.77017713e-01  2.35441223e-01  7.77372122e-02 -3.39478999e-01\n",
            "  9.68081057e-02 -2.28142321e-01 -7.28664219e-01  8.63404348e-02\n",
            " -1.11591361e-01  2.06894875e-01  1.49416357e-01  5.22524297e-01\n",
            " -9.91706401e-02  1.85153633e-01  6.06957786e-02 -1.33973062e-02\n",
            " -2.48451412e-01 -4.45645675e-02  4.03731823e-01 -8.17536842e-03\n",
            " -2.35355809e-01 -2.66317446e-02  2.66809672e-01 -2.74654090e-01\n",
            " -8.45189169e-02  4.34139043e-01  1.92572698e-01 -2.24256232e-01\n",
            " -5.40300980e-02  4.23674425e-03 -3.69370669e-01 -6.21965267e-02\n",
            " -2.31034644e-02 -1.99076459e-01  4.68867898e-01  1.97858766e-01\n",
            " -4.06963170e-01 -5.72992004e-02  2.11443249e-02 -2.08095133e-01\n",
            " -5.12209594e-01 -1.34378165e-01 -2.03165710e-01  1.92875862e-01\n",
            " -1.51826471e-01 -1.74800336e-01 -3.03933024e-01 -2.48019040e-01\n",
            "  2.00775340e-01 -1.57498289e-02 -4.47277516e-01 -1.09597512e-01\n",
            "  1.01331823e-01  4.83031064e-01  8.08230340e-02 -2.60164827e-01\n",
            "  3.98613483e-01  1.34095609e-01 -1.02527015e-01  1.39220715e-01\n",
            "  1.48946136e-01 -2.25794360e-01  4.10318345e-01  4.07175981e-02\n",
            "  6.43390715e-02 -1.24587797e-01 -1.68087617e-01  1.20412141e-01\n",
            " -1.60753317e-02  1.60780415e-01 -8.03923905e-02 -1.43601652e-02\n",
            " -3.80986296e-02 -3.01220626e-01 -6.84610426e-01  2.71218985e-01\n",
            " -1.23222545e-01  3.15927029e-01 -2.62211859e-01 -8.74977633e-02\n",
            " -2.25148305e-01 -1.04314916e-01  3.90128493e-01 -1.91030324e-01\n",
            " -3.72590363e-01 -2.41869707e-02  1.08332418e-01 -5.17278135e-01\n",
            "  3.69769752e-01  3.46002460e-01 -1.60638109e-01 -1.87597468e-01\n",
            " -3.24134715e-02 -1.20695852e-01 -6.63931131e-01  1.73869237e-01\n",
            " -5.17110527e-01  8.58018845e-02 -1.18702479e-01 -1.75527811e-01\n",
            " -2.56476760e-01 -4.20339368e-02 -4.59793489e-03  8.71980637e-02\n",
            " -6.70463026e-01 -1.16606236e-01 -1.40473500e-01  3.69678408e-01\n",
            " -4.88168269e-01 -1.29651144e-01 -6.58637956e-02 -2.07701340e-01\n",
            " -2.20543489e-01  3.89832295e-02 -3.79233539e-01  1.26047462e-01\n",
            "  1.45196700e-02  5.36048692e-03 -1.64330721e-01 -2.14910313e-01\n",
            "  1.59996331e-01 -1.61293313e-01  3.95684421e-01 -2.11055979e-01\n",
            "  2.36636579e-01 -1.59869105e-01 -1.84806243e-01  2.06380546e-01\n",
            " -6.10931404e-02 -4.41361070e-02 -7.24353120e-02 -1.11384720e-01\n",
            " -2.14560792e-01 -4.04956222e-01  3.50769162e-01 -3.46670896e-01\n",
            " -1.24862321e-01 -1.32202744e-01  5.05553372e-02 -3.61658335e-01\n",
            " -1.50045887e-01 -6.88554525e-01 -8.36701319e-02  5.08292735e-01\n",
            "  4.53601658e-01 -1.63623139e-01 -1.44088447e-01  3.64095718e-01\n",
            "  4.58357930e-01  2.94686347e-01  2.94674963e-01  1.50811329e-01\n",
            "  3.05927962e-01  6.79750681e-01 -2.71332324e-01 -3.94097827e-02\n",
            "  8.35608542e-02  6.77263066e-02 -1.76611423e-01  4.28613544e-01\n",
            " -5.40159196e-02 -6.17789254e-02  1.54477403e-01  3.49179059e-01\n",
            "  1.10735767e-01 -3.95283192e-01 -1.42841395e-02 -1.48894129e+01\n",
            "  9.06172097e-02  3.88087153e-01  9.70184878e-02 -3.27503949e-01\n",
            "  7.58866906e-01 -1.13589719e-01  5.60584366e-01 -3.80249202e-01\n",
            " -5.36995381e-02 -2.96183795e-01  4.65237021e-01  5.32712825e-02\n",
            "  2.99152672e-01  1.42890871e-01 -2.76768152e-02 -3.06556612e-01\n",
            " -2.56880105e-01 -6.87825084e-02 -1.05204105e-01 -4.31091897e-02\n",
            " -1.71693221e-01  3.58199149e-01  2.23307371e-01 -3.27017233e-02\n",
            "  1.78744495e-01 -2.34231994e-01 -6.64178208e-02  9.80324298e-02\n",
            " -6.85765967e-02 -3.27132829e-02  1.12931184e-01 -2.42113229e-02\n",
            " -2.58598546e-03  1.20686889e-01 -4.16777343e-01 -3.32021385e-01\n",
            " -4.75439757e-01  1.41271099e-01  3.27064782e-01 -7.79027939e-01\n",
            "  8.32745492e-01 -1.48570433e-01  1.88909993e-01  1.40693650e-01\n",
            " -5.12203574e-01  5.86638033e-01  7.61143491e-02  1.18304612e-02\n",
            "  1.27414605e-02  3.30742970e-02 -5.38933814e-01 -3.59005302e-01\n",
            "  2.55216926e-01 -1.01495154e-01 -4.15222853e-01 -3.75182062e-01\n",
            " -3.88126075e-02  6.02085963e-02  1.11868270e-01  1.26523805e+00\n",
            " -1.64959610e-01  1.63909778e-01 -1.09757826e-01  4.06359851e-01\n",
            "  1.07467979e-01 -2.20732361e-01 -1.10919766e-01  1.04626611e-01\n",
            " -1.13665178e-01  4.98480618e-01  1.99218452e-01 -6.84093893e-01\n",
            " -2.91131437e-01  1.78709090e-01 -2.20681712e-01 -2.66332507e-01\n",
            " -3.96197498e-01  3.12799960e-01 -5.81078351e-01  3.70134339e-02\n",
            " -7.38818422e-02 -1.33644447e-01  2.43414745e-01  1.62741557e-01\n",
            "  2.38937721e-01 -1.48078337e-01 -5.48101105e-02 -7.95372427e-02\n",
            " -1.12821318e-01  8.74321535e-02 -1.72775090e-01 -7.43799359e-02\n",
            "  1.75293729e-01 -9.21252221e-02 -1.40001148e-01 -3.17458659e-01\n",
            "  5.00483930e-01  1.42715290e-01  6.44434467e-02  2.25570351e-01\n",
            "  5.66226542e-01  2.51076639e-01  1.56637922e-01 -3.40443343e-01\n",
            " -3.02970588e-01  4.36251909e-02 -7.38225356e-02  4.16421920e-01\n",
            " -2.70752639e-01  4.31246400e-01  1.40938938e+00 -1.51066512e-01\n",
            "  2.18140587e-01  5.60130253e-02  8.81853849e-02 -5.34234494e-02\n",
            "  6.12393580e-02 -1.75980657e-01 -3.10269535e-01 -3.23086418e-02\n",
            "  5.29503562e-02 -1.14719719e-01 -8.33759665e-01  3.12979668e-01\n",
            " -2.54820257e-01 -1.08777568e-01  3.53102326e-01 -2.19918296e-01\n",
            " -2.61484027e-01 -5.15506268e-02  1.67456195e-01 -5.06488532e-02\n",
            "  3.50662172e-01 -1.52382001e-01  1.30260885e-01 -1.17526166e-02\n",
            "  1.70485035e-01 -1.47653997e-01 -1.23682886e-01 -4.26600315e-02\n",
            " -1.74227729e-01  1.12258315e-01 -1.04057856e-01 -6.61725327e-02\n",
            " -8.17795694e-02 -1.43173393e-02 -5.66844828e-02  1.31981567e-01\n",
            " -1.71599045e-01  9.05026868e-02  1.21942051e-01 -1.88035622e-01\n",
            "  1.13584921e-01  1.23137921e-01  1.14695840e-01 -3.56194302e-02\n",
            "  1.35019422e-02 -2.99399942e-01  1.09430768e-01  1.36342913e-01\n",
            " -2.84788877e-01 -2.47769982e-01 -2.46369585e-01  5.97763173e-02\n",
            " -2.85794675e-01  3.57406177e-02  1.77432060e-01  6.38737977e-01\n",
            " -1.97893918e-01  4.33004275e-02  1.16748646e-01 -4.44752574e-01\n",
            " -8.82672425e-03  1.08431011e-01  1.21462919e-01  1.08451933e-01\n",
            "  1.43101558e-01 -1.53814688e-01  5.46022594e-01  5.22197857e-02\n",
            " -4.96545613e-01 -2.94690818e-01  2.64066517e-01  1.84016511e-01\n",
            " -3.57571095e-01  1.20079374e+00  2.18642373e-02 -5.25721133e-01]\n",
            "___________ Sample Sentiment ___________ \n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(\"___________ Sample Embedding ___________ \")\n",
        "print(X[100])\n",
        "print(\"___________ Sample Sentiment ___________ \")\n",
        "print(Y[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFuU5JL9rn2o"
      },
      "source": [
        "As you can see, X is a very long (768 dimensional) embedding of the aspect, while Y is the ID of the sentiment label (in this case 3)\n",
        "\n",
        "Let's split X and Y now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGUVJ_K6rn2p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, shuffle=True, random_state=42, stratify=Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8gK5kWrn2p"
      },
      "source": [
        "#### B.6 Train a ML Classifier on the Embeddings\n",
        "\n",
        "Finally let's train a simple Linear SVM on the Embeddings. You can of course try to experiment with the classifier you want to use. Depending on the size of the data and the amount of labels, there might be other better options. Some commonly used classifiers include Decision Trees, Multi-layer Perceptron, Random Forests, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_aCgNBern2p",
        "outputId": "e6374fdc-a0cf-4baa-dd6e-58fddde62922"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=0.025, kernel='linear')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel=\"linear\", C=0.025)\n",
        "\n",
        "classifier.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKka-yBIrn2q"
      },
      "source": [
        "Our  model is trained! Let's find it out how accurate it is on the Test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCUn7680rn2q",
        "outputId": "eb2530ce-3bab-48de-f139-55a2d0cf5a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.14      0.25        14\n",
            "           1       0.62      0.62      0.62        64\n",
            "           2       0.35      0.24      0.28        38\n",
            "           3       0.67      0.88      0.76       130\n",
            "           4       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.63       265\n",
            "   macro avg       0.53      0.38      0.38       265\n",
            "weighted avg       0.58      0.63      0.58       265\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = classifier.predict(X_test)\n",
        "print(classification_report(y_test, predictions, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex12OgFDrn2q"
      },
      "source": [
        "As you can see, our model has an accuracy of 63% with less than 1000 labeled aspects labelled with sentiment used for training!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}