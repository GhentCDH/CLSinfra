{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3AyfOcM9jpW"
      },
      "source": [
        "# Chain of Thought for NER with Llama 3.1.\n",
        "\n",
        "## Open-weights LLM (Llama3.1 8B)\n",
        "\n",
        "Large Language Models (LLMs) have reshaped natural language processing (NLP), offering powerful capabilities in tasks like information extraction (IE) from historical texts. Chat-based generative models completely change the way we can interact with and analyse our corpora. These models enable users to engage with training data using natural language, revolutionizing communication paradigms and propagating a wide adoption of AI-tools across text-based tasks. However, concerns about **data privacy**, and **access** have arisen due to the dominance of closed-source models from industry giants like OpenAI and Google. To address these issues, there's a growing interest in open-weights alternatives, which provide transparency and control over models and data.\n",
        "\n",
        "This Jupyter Notebook explores the potential of open-weights LLMs for NER and aspect recognition in historical texts. We'll showcase zero- and few-shot learning to overcome **data scarcity**, a pivotal problem in applying IE in literary-historical contexts. We aim to showcase how open-source LLMs can illuminate the past and shape the future of historical scholarship!\n",
        "\n",
        "\n",
        "The Notebook showcases the following procedures:\n",
        "\n",
        "\n",
        "\n",
        "1.  **Chain of Thought with Few-shot NER/aspect extraction.**\n",
        "\n",
        "    *   With [LLama3.1 8B](https://ai.meta.com/blog/meta-llama-3-1/) (**multilingual model trained on English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai**). More information [HugginFace](https://huggingface.co/meta-llama/Llama-3.1-8B)\n",
        "\n",
        "\n",
        "\n",
        "We implement the code using the package **[LangChain](https://www.langchain.com/)**, a popular wrapper around both closed and open-source LLMs. The models run in [TogetherAi service](https://www.together.ai/) and you will need and API-Key for executing this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkiva6QO8fHC"
      },
      "source": [
        "# 1.- Required background knowledge üß†\n",
        "\n",
        "‚ùóüéì To adapt and use this Notebook to produce entities for your own texts, you need to have an intuitive understanding of the following concepts:\n",
        "\n",
        "\n",
        "\n",
        "*   [named entity recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)\n",
        "*   prompting\n",
        "    * few-shot modelling\n",
        "    *   zero-shot modelling\n",
        "    *   Chain of thought\n",
        "*   Large Language Models (generative AI)\n",
        "*   [HuggingFace model hub](https://huggingface.co/)\n",
        "*   [BIO-labels / span evaluation](https://pypi.org/project/nervaluate/)\n",
        "*   Evaluation metrics (F1, accuracy, precision, recall)\n",
        "*   GitHub\n",
        "*   [LangChain](https://www.langchain.com/)\n",
        "*   [Together.ai](https://www.together.ai/)\n",
        "\n",
        "\n",
        "To adapt the code, you need to know about:\n",
        "\n",
        "\n",
        "* Functions and classes in Python\n",
        "* Pandas dataframe operations\n",
        "* Jupyter Notebooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJZ2qVpCzIoB"
      },
      "source": [
        "# 2.- Load packages üìö\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First of all we are going to setup the enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeRO0VLszexB",
        "outputId": "60932b20-0756-40de-e39e-11209a45dcfb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#pip install -r requirements\n",
        "!pip install langchain nervaluate langchain-community langchain-core\n",
        "!pip install session-info\n",
        "!pip install --upgrade langchain-together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5SB0BJUlzIoH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import ast\n",
        "from pydantic import BaseModel\n",
        "from pydantic_core import from_json\n",
        "import glob\n",
        "from typing import List, Optional\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_together import ChatTogether"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "kChrPfwyD9__",
        "outputId": "3ab75f07-0b64-435b-a460-bc26fe300f5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function session_info.main.show(na=True, os=True, cpu=False, jupyter=None, dependencies=None, std_lib=False, private=False, write_req_file=False, req_file_name=None, html=None, excludes=['builtins', 'stdlib_list'])>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import session_info\n",
        "session_info.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsrR0GxLzIoL"
      },
      "source": [
        "# 3.- Set environment ‚ùó\n",
        "\n",
        "\n",
        "**IMPORTANT STEP**: before you can proceed with the code in this Notebook, you have to request an API token from Togeher.AI. Make an account on the website, and follow their directions to create a token. This ensures that HuggingFace controls how many API calls you can make.\n",
        "Also select your model from the list of available models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TOGETHER_API_KEY= add your API key here\n",
        "model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyGlgl8OzIoM"
      },
      "source": [
        "# 4.- Chain of thought with Few-shoot NER/aspect extraction\n",
        "\n",
        "\n",
        "Here, we'll use the framework LangChain to send a request to the open-source generative LLM to extract aspects from our texts.\n",
        "\n",
        "The model choice is a  model id which the user can adjust according to their needs.\n",
        "As an example, we're using the multilingual generative LLM **meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo**.\n",
        "\n",
        "We construct a structured prompt example for the model to extract entities/aspects from the texts in several categories, which you can fully adapt to your needs and texts.\n",
        "\n",
        "**CATEGORIES**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The entities and categories we will focus on in this notebook are the following:\n",
        "- **FAUNA**\n",
        "- **FLORA**\n",
        "- **PERSON**\n",
        "- **LOCATION**\n",
        "- **ORGANISATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1McPbxhD-uab"
      },
      "source": [
        "## 4.1 To Validate the output of the LLM\n",
        "\n",
        "We want our prompt to return our NER-results as a valid JSON output. However, LLMs tend to output incomplete or invalid JSON-schemas, or hallucinates output. Luckily, **Pydantic** is a library which can fix these issues.\n",
        "\n",
        "First, we'll construct a **Pydantic Class** to assert which data types we expect from the model output for each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0aMLocD0Y3Hc"
      },
      "outputs": [],
      "source": [
        "class NER(BaseModel):\n",
        "    \"\"\"\n",
        "\n",
        "    This class asserts the data types we expect from the output of the LLM.\n",
        "      person: Optionally a list, otherwise None.\n",
        "      organisation: Optionally a list, otherwise None\n",
        "      location:\n",
        "      fauna:\n",
        "      flora:\n",
        "    \"\"\"\n",
        "    person: Optional[list] = None\n",
        "    organisation: Optional[list] = None\n",
        "    location: Optional[list] = None\n",
        "    fauna: Optional[list] = None\n",
        "    flora: Optional[list] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844z9p-U_zPN"
      },
      "source": [
        "Let's test this out! We'll try to simulate an incomplete JSON output and feed it to our class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h1-Lhjw2Y32P"
      },
      "outputs": [],
      "source": [
        "#Example of validation\n",
        "partial_json = '{\"location\": [\"Rome\"], \"person\": [\"pepe\", \"Capt. Cook\"], \"random\": [\"hallucination\"]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Tk2QtcY34V",
        "outputId": "6a4e9fda-cab6-422e-a301-5d6ac87d6c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER(person=['pepe', 'Capt. Cook'], organisation=None, location=['Rome'], fauna=None, flora=None)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "__main__.NER"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Example of validation\n",
        "validator = NER.model_validate(from_json(partial_json,allow_partial=True))\n",
        "\n",
        "print(repr(validator))\n",
        "type(validator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxN6GQ7MAdnq"
      },
      "source": [
        "As you can see, the class helps us to parse out the objects which are interesting to our use-case. As you can see, **hallucinations in the output are ignored**, and **the partial JSON-object is validated** automatically!\n",
        "\n",
        "\n",
        "Now we can easily take the attributes from our validator!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgjBIXQHBTpR",
        "outputId": "88c33edb-40df-4a0d-b751-ef5ad3bf24f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pepe', 'Capt. Cook']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Example of validation\n",
        "validator.person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2.- START PLAYING : WRITE YOUR SENTENCE HERE. \n",
        "Code for una simple sentence. Change the content of the sentence variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qX312StFXwx"
      },
      "source": [
        "### 4.2.1 Build a prompt\n",
        "\n",
        "By means of experiment, we will feed several pieces of information to the LLM which we deem interesting to our use-case.\n",
        "Similar to modelling, there are no clear-cut ways to build a prompt; and it's **all a matter of experimentation**!\n",
        "\n",
        "üß†‚ùó Play around with the question, personality, and template!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z0vE15x2Fyka"
      },
      "outputs": [],
      "source": [
        "sentence = \"I was walking in Rome when I saw a beautiful deer and rabbits. I wanted to touch it but it ran through the dandelions.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zfB4ez6HFhVu"
      },
      "outputs": [],
      "source": [
        "# specify the question/request posed to the LLM\n",
        "\n",
        "question = \"Extract the relevant entities from the given sentence.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tg-FZN1KFfZ9"
      },
      "outputs": [],
      "source": [
        "# specify the personality you expect from the LLM\n",
        "\n",
        "personality = \"You are a historian and literary scholar with expertise on historical travel literature, colonial literature and labelling named entities.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YB4HrrnZFkDl"
      },
      "outputs": [],
      "source": [
        "# add a JSON object with the category names followed by the expected data type\n",
        "\n",
        "schema_entity={\"person\": [\"string\"],\n",
        "        \"location\": [\"string\"],\n",
        "        \"fauna\": [\"string\"],\n",
        "        \"flora\": [\"string\"],\n",
        "        \"organisation\": [\"string\"]\n",
        "      }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WsZbvujCFdbb"
      },
      "outputs": [],
      "source": [
        "# add the category names with small global introduction/definition as a string\n",
        "\n",
        "categories = \"\"\"\n",
        "person: proper names of people,\n",
        "location: proper names of locations,\n",
        "fauna: common and scientific names of animals and fauna,\n",
        "flora: common and scientific names of vegetation, plants, flowers and flora,\n",
        "organisation: proper names of organisations\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This brings all the elements above together in a template.\n",
        "# The sentence is clearly indicated by <<<>>>, which helps the model to stick to the text given.\n",
        "\n",
        "template_0=f\"{personality}\"\n",
        "\n",
        "template_1= f\"\"\"\n",
        "Your task is to extract relevant named entities from the given sentence based on the following labels:\n",
        "{categories}\n",
        "Only respond in JSON format, Do not add any more comment.\n",
        "The structure of the JSON format is like this:\n",
        "      {schema_entity} \n",
        "\n",
        "Let's approach this step-by-step:\n",
        "\n",
        "Example 1:\n",
        "Sentence: <<<The New York Zoo is home to jaguars and giant water lilies.>>>\n",
        "\n",
        "Step 1: Identify potential named entities\n",
        "- New York Zoo\n",
        "- jaguars\n",
        "- giant water lilies\n",
        "\n",
        "Step 2: Categorize each entity and asign a label\n",
        "- New York Zoo: organization (Zoo)\n",
        "- New York:location (proper name of a city)\n",
        "- jaguars: fauna (common name of an animal)\n",
        "- giant water lilies: flora (common name of a plant)\n",
        "\n",
        "Step 3: Format the output\n",
        "\n",
        "   {{\"person\": [],\n",
        "    \"location\": [\"New York\"],\n",
        "    \"fauna\": [\"jaguars\"],\n",
        "    \"flora\": [\"giant water lilies\"],\n",
        "    \"organisation\": [\"New York Zoo\"]\n",
        "   }}  \n",
        "    \n",
        "Example 2:\n",
        "Sentence: <<<Hurricane Katrina devastated New Orleans in 2005>>>\n",
        "\n",
        "Step 1: Identify potential named entities\n",
        "- New Orleans\n",
        "\n",
        "Step 2: Categorize each entity and asign a label\n",
        "- New Orleans: location (proper name of a city)\n",
        "\n",
        "Step 3: Format the output\n",
        "\n",
        "   {{\"person\": [],\n",
        "    \"location\": [\"New Orleans\"],\n",
        "    \"fauna\": [],\n",
        "    \"flora\": [],\n",
        "    \"organisation\": []\n",
        "  }}\n",
        "\n",
        "Example 3:\n",
        "Sentence: <<<The Great Wall of China stretches across the Gobi Desert, where Bactrian camels roam freely.>>>\n",
        "\n",
        "Step 1: Identify potential named entities\n",
        "- China\n",
        "- Bactrian camels\n",
        "\n",
        "Step 2: Categorize each entity and asign a label\n",
        "- China: location (name of a Country)\n",
        "- Bactrian camels: fauna (common name of an animal)\n",
        "\n",
        "Step 3: Format the output\n",
        "\n",
        "   {{\"person\": [],\n",
        "    \"location\": [\"China\"],\n",
        "    \"fauna\": [\"Bactrian camels\"],\n",
        "    \"flora\": [],\n",
        "    \"organisation\": [] \n",
        "  }}\n",
        "\n",
        "Now, DO NOT take into account the previous examples, use them JUST AS A REFERENCE. \n",
        "\n",
        "Question: {question}\n",
        "The sentence for analyzing is: <<< {sentence} >>>\n",
        "\n",
        "Answer: \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.2 Calling the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER(person=['I'], organisation=[], location=['Rome'], fauna=['deer', 'rabbits'], flora=['dandelions'])\n"
          ]
        }
      ],
      "source": [
        "llm = ChatTogether(\n",
        "      model=model,\n",
        "      temperature=0,\n",
        "      api_key=TOGETHER_API_KEY,\n",
        "  )\n",
        "messages=[\n",
        "        (\n",
        "\n",
        "            \"system\", template_0,\n",
        "        ),\n",
        "        (\n",
        "            \"human\",template_1,\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "result = NER.model_validate(from_json(response.content, allow_partial=True))\n",
        "print(repr(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.3 Check the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQqW5r5OHdWd",
        "outputId": "670e98fb-4206-4bd9-948f-4cb7f5999044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['deer', 'rabbits']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.fauna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvcyz1pjHFwJ",
        "outputId": "9d2b0565-477b-49e2-bb2b-a9edfa45d868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Rome']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3.- START PLAYING : Use your files and ask the model. \n",
        "In case you have your information in a different input format, you'll have to read them and load them as a dataframe. This code processes all rows of the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLVxG9VszIoN"
      },
      "source": [
        "### 4.3.1 Functions\n",
        "\n",
        "In this section, we write functions for making calls to the LLM and parsing the output. These funtions are used later in the code.\n",
        "\n",
        "\n",
        "1.  In our function *parse_llm_response*, we split the output and only take the element after our \"Answer:\"-section in our prompt. Then, we cast the result to JSON by applying [Pydantic](https://docs.pydantic.dev/latest/concepts/json/) to transform partial JSON outputs to a valid JSON object, parse the entity text and their labels.\n",
        "\n",
        "2.   In our function *llm_output*, we call the LLM anb we obtain a dictionary output.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "‚ùóüí≠ **Mind you that these functions will have to be adapted according to the output of your LLM of choice, given that the output is unpredictable and changes when your prompt does.**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#parse the llm response\n",
        "# cast to json\n",
        "# parse all the entities and their categories\n",
        "\n",
        "def parse_llm_response(response, basemodel_class = NER):\n",
        "  try:\n",
        "    result = basemodel_class.model_validate(from_json(response.content, allow_partial = True))\n",
        "    category_entity = []\n",
        "    for entity in result:\n",
        "      if entity[1] != None: #if the model returned a valid result for the categories which is not None\n",
        "        category = entity[0]\n",
        "        entity_text_list = entity[1]\n",
        "\n",
        "        for ent in entity_text_list:\n",
        "          category_entity.append((ent, category))\n",
        "\n",
        "    return category_entity\n",
        "\n",
        "  except:\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-FTDVwfnzIoP"
      },
      "outputs": [],
      "source": [
        "### call to the LLM and parse the response\n",
        "\n",
        "def llm_output(content_user,model_1=model,content_sys=template_0,basemodel_class = NER):\n",
        "    \n",
        "    llm = ChatTogether(\n",
        "      model=model_1,\n",
        "      temperature=0,\n",
        "      api_key=TOGETHER_API_KEY,\n",
        "  )\n",
        "    messages=[\n",
        "        (\n",
        "            \"system\", content_sys,\n",
        "        ),\n",
        "        (\n",
        "            \"human\",content_user,\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    test_result = basemodel_class.model_validate(from_json(response.content, allow_partial = True))\n",
        "    result = test_result.model_dump()\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGJkItJGPIGx"
      },
      "source": [
        "### 4.3.2 Apply the LLM to a Pandas DataFrame\n",
        "\n",
        "Here, we take a sample of our corpus to showcase a possible approach but the most important take-away is that you can apply this pipeline to your own data!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32WstRkNPnCs"
      },
      "source": [
        "#### 4.3.2.1.- Chunk the text into smaller parts\n",
        "\n",
        "The LLama 3.1 8x7B model takes a maximum input of **128K** tokens. Therefore, we need to split up the text in smaller bits before we proceed if our text is over the limit.\n",
        "\n",
        "Let's split up our text in chunks of 64K tokens, and make a new row for each chunk.\n",
        "\n",
        "The model is probably more inclined to make mistakes when the text chunks are too large. One of the reasons for this is that the models have a tendency to focus on the beginning or the end of an input, and pay less attention to the middle part (this paper [linktekst](https://arxiv.org/pdf/2307.03172) expertly explains it!). On the other hand, there is a [strict rate limit](https://huggingface.co/docs/api-inference/faq) on the HuggingFace API. Experiment with these settings to see if this approach is useful for your use-case!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZwC5Tu07RJ3k"
      },
      "outputs": [],
      "source": [
        "def text_splitter(sample_text, chunk_size = 64000):\n",
        "# Initialize the text splitter with custom parameters\n",
        "  custom_text_splitter = RecursiveCharacterTextSplitter(\n",
        "      # Set custom chunk size\n",
        "      chunk_size = chunk_size,\n",
        "      chunk_overlap  = 20,\n",
        "      # Use length of the text as the size measure\n",
        "      length_function = len,\n",
        "\n",
        "  )\n",
        "\n",
        "  # Create the chunks\n",
        "  texts = custom_text_splitter.create_documents([sample_text])\n",
        "  texts_content = [text.page_content for text in texts]\n",
        "\n",
        "  return texts_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For test purpose execute section 5 to build English_corpus dataframe. Section 5 is BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "43_0nakxY36g"
      },
      "outputs": [],
      "source": [
        "#Example of using text_splitter\n",
        "English_corpus_sample = English_corpus[1:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqSeniXeQJqa",
        "outputId": "50e9632a-c083-4009-a32f-47d34629121e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6q/tttpc5cn2_jg62b4x7cv_5r80000gn/T/ipykernel_93017/4024491078.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  English_corpus_sample[\"chunks\"] = English_corpus_sample.text.apply(text_splitter)\n"
          ]
        }
      ],
      "source": [
        "#Example of using text_splitter\n",
        "English_corpus_sample[\"chunks\"] = English_corpus_sample.text.apply(text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3S4yLdqoY38R"
      },
      "outputs": [],
      "source": [
        "#Example of using text_splitter\n",
        "English_corpus_sample = English_corpus_sample.explode(\"chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.2.2.- Loading in a dataframe and chunking the data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdB6bOGnD9M0"
      },
      "source": [
        "To show you how the LLM works, let's run it on a small sample of our text and print out the prompt and results for each iteration. As you can see, the LLM sometimes outputs incorrect or incomplete JSON-results; which results in a loss of output when the answer is validated and parsed. Because indeed, our validation approach removes invalid JSON objects in the LLM-output, but that means we may also lose some correctly extracted entities.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "‚ùó You have to decide for yourself whether this loss is something you can work with - or you could further experiment with your prompt and validation settings to circumvent this problem as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wTa3GqHXTHhB"
      },
      "outputs": [],
      "source": [
        "#pick a sample of the first ten sentences in our corpus\n",
        "\n",
        "test = English_corpus_sample[:2]\n",
        "test = test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sUUz6Ey4VJxx",
        "outputId": "80416cb3-651a-4efd-983a-c4a24ad8726a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>chunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Florence_and_Northern_Tuscany_with_Genoa.txt</td>\n",
              "      <td>Title: Florence and Northern Tuscany with Geno...</td>\n",
              "      <td>English</td>\n",
              "      <td>Title: Florence and Northern Tuscany with Geno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Florence_and_Northern_Tuscany_with_Genoa.txt</td>\n",
              "      <td>Title: Florence and Northern Tuscany with Geno...</td>\n",
              "      <td>English</td>\n",
              "      <td>It is perhaps in the Via Garibaldi, Via Cairol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file  \\\n",
              "0  Florence_and_Northern_Tuscany_with_Genoa.txt   \n",
              "1  Florence_and_Northern_Tuscany_with_Genoa.txt   \n",
              "\n",
              "                                                text language  \\\n",
              "0  Title: Florence and Northern Tuscany with Geno...  English   \n",
              "1  Title: Florence and Northern Tuscany with Geno...  English   \n",
              "\n",
              "                                              chunks  \n",
              "0  Title: Florence and Northern Tuscany with Geno...  \n",
              "1  It is perhaps in the Via Garibaldi, Via Cairol...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### These are the sentences (chunks) to process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to build your user content and sys template. The sys template is easy to build, you only need to change the cell above. For the user template you need to build one different template for each sentence in each line of the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Title: Florence and Northern Tuscany with Geno...\n",
              "1    It is perhaps in the Via Garibaldi, Via Cairol...\n",
              "Name: chunks, dtype: object"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.2.2.- Building the user and sys prompt. So we need to define them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify the question/request posed to the LLM\n",
        "\n",
        "question = \"Extract the relevant entities from the given sentence.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify the personality you expect from the LLM\n",
        "\n",
        "personality = \"You are a historian and literary scholar with expertise on historical travel literature, colonial literature and labelling named entities.\"\n",
        "template_0=f\"{personality}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add a JSON object with the category names followed by the expected data type\n",
        "\n",
        "schema_entity={\"person\": [\"string\"],\n",
        "        \"location\": [\"string\"],\n",
        "        \"fauna\": [\"string\"],\n",
        "        \"flora\": [\"string\"],\n",
        "        \"organisation\": [\"string\"]\n",
        "      }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add the category names with small global introduction/definition as a string\n",
        "\n",
        "categories = \"\"\"\n",
        "person: proper names of people,\n",
        "location: proper names of locations,\n",
        "fauna: common and scientific names of animals and fauna,\n",
        "flora: common and scientific names of vegetation, plants, flowers and flora,\n",
        "organisation: proper names of organisations\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Now we build a dataframe with the different prompt for the different chunks of each row in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgYtbW4gSlpp",
        "outputId": "ea978754-385f-498e-b9c0-4734a493dfb8"
      },
      "outputs": [],
      "source": [
        "chunk_size=20000\n",
        "templates_text=[]\n",
        "for text in test[\"chunks\"]:\n",
        "  chunks=text_splitter(text, chunk_size)\n",
        "  templates=[]\n",
        "  for sentence in chunks:\n",
        "  \n",
        "    template_1 = f\"\"\"\n",
        "          Your task is to extract relevant named entities from the given sentence based on the following labels:\n",
        "          {categories}\n",
        "          Only respond in JSON format, Do not add any more comment.\n",
        "          The structure of the JSON format is like this:\n",
        "                {schema_entity} \n",
        "\n",
        "          Let's approach this step-by-step:\n",
        "\n",
        "          Example 1:\n",
        "          Sentence: <<<The New York Zoo is home to jaguars and giant water lilies.>>>\n",
        "\n",
        "          Step 1: Identify potential named entities\n",
        "          - New York Zoo\n",
        "          - jaguars\n",
        "          - giant water lilies\n",
        "\n",
        "          Step 2: Categorize each entity and asign a label\n",
        "          - New York Zoo: organization (Zoo)\n",
        "          - New York:location (proper name of a city)\n",
        "          - jaguars: fauna (common name of an animal)\n",
        "          - giant water lilies: flora (common name of a plant)\n",
        "\n",
        "          Step 3: Format the output\n",
        "\n",
        "            {{\"person\": [],\n",
        "              \"location\": [\"New York\"],\n",
        "              \"fauna\": [\"jaguars\"],\n",
        "              \"flora\": [\"giant water lilies\"],\n",
        "              \"organisation\": [\"New York Zoo\"]\n",
        "            }}  \n",
        "              \n",
        "          Example 2:\n",
        "          Sentence: <<<Hurricane Katrina devastated New Orleans in 2005>>>\n",
        "\n",
        "          Step 1: Identify potential named entities\n",
        "          - New Orleans\n",
        "\n",
        "          Step 2: Categorize each entity and asign a label\n",
        "          - New Orleans: location (proper name of a city)\n",
        "\n",
        "          Step 3: Format the output\n",
        "\n",
        "            {{\"person\": [],\n",
        "              \"location\": [\"New Orleans\"],\n",
        "              \"fauna\": [],\n",
        "              \"flora\": [],\n",
        "              \"organisation\": []\n",
        "            }}\n",
        "\n",
        "          Example 3:\n",
        "          Sentence: <<<The Great Wall of China stretches across the Gobi Desert, where Bactrian camels roam freely.>>>\n",
        "\n",
        "          Step 1: Identify potential named entities\n",
        "          - China\n",
        "          - Bactrian camels\n",
        "\n",
        "          Step 2: Categorize each entity and asign a label\n",
        "          - China: location (name of a Country)\n",
        "          - Bactrian camels: fauna (common name of an animal)\n",
        "\n",
        "          Step 3: Format the output\n",
        "\n",
        "            {{\"person\": [],\n",
        "              \"location\": [\"China\"],\n",
        "              \"fauna\": [\"Bactrian camels\"],\n",
        "              \"flora\": [],\n",
        "              \"organisation\": [] \n",
        "            }}\n",
        "\n",
        "          Now, DO NOT take into account the previous examples, use them JUST AS A REFERENCE. \n",
        "\n",
        "          Question: {question}\n",
        "          The sentence for analyzing is: <<< {sentence} >>>\n",
        "\n",
        "          Answer: \"\"\"\n",
        "    templates.append(template_1)\n",
        "  templates_text.append(templates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.2.3 Executing NxM prompts\n",
        "In this section we execute NxM prompts, where N stands for the number of files and M for the number of chunks per file. All the results are merged in only one dictionary with the NER structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'person': ['Edward Hutton', 'John Evelyn', 'Tennyson', 'Philip of Spain', 'Visconti', 'Cesare Borgia', 'St. Catherine Adorni', 'Andrea Doria', 'St. Nazarus', 'St. Celsus', 'St. Laurence', 'St. Augustine', 'Luitprand', 'Charlemagne', 'Otho', 'Godfrey de Bouillon', 'Urban II', 'Peter the Hermit', 'Guglielmo Embriaco', 'Nicodemus', 'Napoleon', 'Andrea Doria', 'Simone Boccanegra', 'Gian Galeazzo Visconti', 'Filippo Maria Visconti', 'Tommaso Fregosi', 'Francesco Spinola', 'Pietro Fregosi', 'Charles VIII', 'Mahomet', 'Sforza', 'Galeazzo', 'Ludovico Sforza', 'Louis XII', 'Columbus', 'Columbus', 'David', 'Louis of France', 'Francis I', 'Julius II', 'Charles V', 'Andrea Doria', 'Giannettino', 'Gian Luigi Fieschi', 'Abbate di San Fruttuoso', 'Guglielmo Boccanegra', 'Luca Pinelli', 'Pope Alexander III', 'Richard Cordelion', 'Federigo Barbarossa', 'Henry IV', 'Innocent IV', 'Henry VII', 'St. Catherine of Siena', 'St. Catherine Adorni', 'Louis XII', 'Don John of Austria', 'Velasquez', 'Vandyck', 'Giustiniani', 'Pallavicini', 'Guido Reni', 'Rubens', 'Garibaldi', 'Pagano Doria', 'Luciano Doria', 'Oberto Doria', 'Filippino Doria', 'Andrea Morosini', 'Loto', 'Count Ugolino', 'Andrea', 'Montorsoli', 'Pope Paul III', 'Andrea Doria', 'Giovandrea', 'Galeazzo Alessi', 'Vandyck', 'Rubens', 'Titian', 'Giambattista Nani', 'Velasquez', 'John Evelyn', 'Simone Boccanegra', 'Urban V', 'Urban VI', 'Francisco Maria Balbi', 'Tornson', 'Bartolommeo Bianco', 'Giovanni da Bologna', 'Bacon', 'Sirus', 'Carlone', 'Paganini', 'Sarasate', 'Se√±or Sarasate', 'Leonardo', 'Spenser', 'Giorgione', 'Della Porta', 'Rocco Lurago', 'Franco Lercaro', 'Alessandro Farnese', 'James I of England', 'Philip IV of Spain', 'Philip II of Spain', 'Francesco Maria Balbi', 'Justi', 'Le Mesurier', 'Shelley', 'Mary', 'Claire', 'Trelawney', 'Williams', 'Byron', 'Charles V', 'Francis I', 'Jesus', 'Petrarch', 'Guido', 'S. Margherita', 'Claire', 'Shelley', 'Williams', 'Trelawney', 'Leigh Hunt', 'Vincent Eyre', 'Dr. Garnett', 'Professor Dowden', 'Byron', 'Eyre', 'Aeschylus', 'Keats', 'Tommaso Parentucelli', 'Vespasiano da Bisticci', \"Cosimo de' Medici\", 'Rinaldo degli Albizzi', 'Palla Strozzi', 'Filelfo', 'Manetti', 'Tomaso da Serezano', 'Pope Nicholas V', 'Vespasiano', 'Messer Rinaldo degli Albizzi', 'Messer Palla di Nofri Strozzi', 'Pius II', 'Sigismondo Malatesta', 'Virgil', 'Cassandra'], 'organisation': ['Bank of St. George', 'Bank of St. George', 'Order of the Franciscans', 'The Most Holy Trinity', 'The Bank of St. George', 'The Grand Council', 'The Senate', 'The Golden Book', \"Il Libro d'Oro\", 'The Parliament', 'The Grand Council of Four Hundred', 'The H√¥tel de la Ville', 'The Municipality', 'Commune of Genoa', 'Venetian fleet', 'Spanish galleys', 'Pisan fleet', \"Doria's galleys\", \"Pope's galleys\", 'Genoese school', 'New York Zoo', 'Genoese Government', 'New York Zoo', 'Ariel', 'Bolivar', 'Times'], 'location': ['Genoa', 'Italy', 'London', 'Marseilles', 'Nice', 'Mentone', 'Ventimiglia', 'Turin', 'Cagliari', 'Pavia', 'Albaro', 'Via di Pr√®', 'Via S. Luca', 'S. Siro', 'S. Stefano', 'S. Agostino', 'Corsica', 'Monaco', 'Genoa', 'Jerusalem', 'Joppa', 'Antioch', 'Cesarea', 'Tyre', 'Acre', 'Palestine', 'Europe', 'Lombardy', 'Monaco', 'Pera', 'Caffa', 'Bosphorus', 'Euxine', 'Constantinople', 'Pisa', 'Corsica', 'Spain', 'Almeria', 'Tortosa', 'Crete', 'Meloria', \"Bocca d'Arno\", 'Sapienza', 'Greece', 'Milan', 'Rimini', 'Naples', 'Navarre', 'Florence', 'Galata', 'Ancona', 'Cadiz', 'Salamanca', 'Seville', 'New Orleans', 'Gobi Desert', 'China', 'Genoa', 'Pisa', 'Rome', 'France', 'Savona', 'Palermo', 'Naples', 'Oneglia', 'Constantinople', 'Porto Pisano', 'Banca di S. Giorgio', 'Via S. Lorenzo', 'Piazza Banchi', 'Strada degli Orefici', 'Piazza Umberto Primo', 'Piazza Deferrari', 'Strada S. Matteo', 'S. Fruttuoso', 'Portofino', 'Curzola', 'Savona', 'S. Matteo', 'Greece', 'Island of Sapienza', 'Genoa', 'Gulf of the Venetians', 'Pola', 'Pisan waters', 'Gulf of Salerno', 'Civitavecchia', 'Florence', 'Sicily', 'S. Matteo', 'Piazza Deferrari', 'Via Carlo Felice', 'Piazza Fontane Marose', 'Palazzo Pallavicini', 'Palazzo della Casa', 'Palazzo Spinola', 'Palazzo Negrone', 'Via Nuova', 'Acqua Sola', 'Genoa', 'Via Garibaldi', 'Piazza Marose', 'Palazzo Cambiaso', 'Palazzo Gambaro', 'Palazzo Parodi', 'Palazzo Carega', 'Palazzo Spinola', 'Palazzo Giorgio Doria', 'Palazzo Adorno', 'Palazzo Serra', 'Palazzo Municipale', 'Palazzo Rosso', 'Palazzo Bianco', 'Palazzo Durazzo-Pallavicini', 'Palazzo Balbi', \"Palazzo dell' Universit√†\", 'Palazzo Reale', 'Palazzo Doria', 'S. Siro', 'Piazza Zecca', 'Piazza Annunziata', 'Via Balbi', 'Piazza Acquaverde', 'Nervi', 'Via Corsica', 'Piazza Deferrari', 'Carrara', 'Firenze', 'Rome', 'Babylon', 'Milan', 'Venice', 'Mantua', 'Rouen', 'Edinburgh', 'England', 'Antwerp', 'Brussels', 'Prado', 'Italy', 'Europe', 'Genoa', 'Tuscany', 'Spezia', 'Riviera di Levante', 'Europe', 'Nice', 'Mentone', 'Castellamare', 'Sorrento', 'Vietri', 'Amalfi', 'Paestum', 'Porto Venere', 'Gobi Desert', 'China', 'Nervi', 'Recco', 'Camogli', 'Rapallo', 'Portofino', 'San Fruttuoso', 'Cervara', 'S. Margherita', 'S. Michele di Pagana', 'Chiavari', 'Sestri-Levante', 'Spezia', 'Lerici', 'San Terenzo', 'Livorno', 'Montenero', 'Sarzana', 'Italy', 'Lerici', 'Florence', 'San Terenzo', 'Porto Venere', 'Genoa', 'Leghorn', 'Pisa', 'Arno', 'Tuscany', 'Italy', 'Viareggio', 'Livorno', 'Gulf of Spezia', 'Spezia', 'Lucca', 'Lunigiana', 'Sarzana', 'Macra', 'Luna', 'Rome', 'Vatican', 'S. Pietro', 'Magna Graecia', 'Pisa', 'Sarzana', 'Florence', 'Bologna', 'Rimini', 'Luna', 'Porto Venere', 'Massa', 'Troy', 'Siena'], 'fauna': ['Bactrian camels', 'jaguars', 'Bactrian camels', 'gulls', 'oxen', 'shepherds', 'kings', 'cicale', 'peasant girls', 'Bactrian camels', 'cicale', 'osier', 'eagles', 'skylark'], 'flora': ['orange groves', 'olives', 'orange gardens', 'flaming oleanders', 'magnolia', 'pomegranate', 'wild-flowers', 'cypress', 'ilex', 'myrtle', 'vines', 'black and white marble', 'giant water lilies', 'agaves', 'olives', 'corn', 'cypress', 'ilex', 'olive', 'flowers', 'trees', 'grapes', 'nespoli', 'oranges']}\n"
          ]
        }
      ],
      "source": [
        "# Diccionario acumulador para los resultados finales\n",
        "final_result = {}\n",
        "for templates in templates_text:\n",
        "    # Diccionario calculado en el bucle interno\n",
        "    # Combinar resultado_actual con resultado_final\n",
        "    for sub_template in templates:\n",
        "        sub_result=llm_output(sub_template,model,template_0) \n",
        "        for clave, value in sub_result.items():\n",
        "            if clave in final_result:\n",
        "                # Sumar valores si es lista\n",
        "                if isinstance(value, list):\n",
        "                    final_result[clave] += value\n",
        "                # Otros tipos pueden manejarse seg√∫n se necesite\n",
        "            else:\n",
        "                # Si la clave no existe en resultado_final, a√±adirla\n",
        "                final_result[clave] = value\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(final_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.2.4 Checking and saving results\n",
        "You can check the output list based on the category dictionary keys!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Edward Hutton',\n",
              " 'John Evelyn',\n",
              " 'Tennyson',\n",
              " 'Philip of Spain',\n",
              " 'Visconti',\n",
              " 'Cesare Borgia',\n",
              " 'St. Catherine Adorni',\n",
              " 'Andrea Doria',\n",
              " 'St. Nazarus',\n",
              " 'St. Celsus',\n",
              " 'St. Laurence',\n",
              " 'St. Augustine',\n",
              " 'Luitprand',\n",
              " 'Charlemagne',\n",
              " 'Otho',\n",
              " 'Godfrey de Bouillon',\n",
              " 'Urban II',\n",
              " 'Peter the Hermit',\n",
              " 'Guglielmo Embriaco',\n",
              " 'Nicodemus',\n",
              " 'Napoleon',\n",
              " 'Andrea Doria',\n",
              " 'Simone Boccanegra',\n",
              " 'Gian Galeazzo Visconti',\n",
              " 'Filippo Maria Visconti',\n",
              " 'Tommaso Fregosi',\n",
              " 'Francesco Spinola',\n",
              " 'Pietro Fregosi',\n",
              " 'Charles VIII',\n",
              " 'Mahomet',\n",
              " 'Sforza',\n",
              " 'Galeazzo',\n",
              " 'Ludovico Sforza',\n",
              " 'Louis XII',\n",
              " 'Columbus',\n",
              " 'Columbus',\n",
              " 'David',\n",
              " 'Louis of France',\n",
              " 'Francis I',\n",
              " 'Julius II',\n",
              " 'Charles V',\n",
              " 'Andrea Doria',\n",
              " 'Giannettino',\n",
              " 'Gian Luigi Fieschi',\n",
              " 'Abbate di San Fruttuoso',\n",
              " 'Guglielmo Boccanegra',\n",
              " 'Luca Pinelli',\n",
              " 'Pope Alexander III',\n",
              " 'Richard Cordelion',\n",
              " 'Federigo Barbarossa',\n",
              " 'Henry IV',\n",
              " 'Innocent IV',\n",
              " 'Henry VII',\n",
              " 'St. Catherine of Siena',\n",
              " 'St. Catherine Adorni',\n",
              " 'Louis XII',\n",
              " 'Don John of Austria',\n",
              " 'Velasquez',\n",
              " 'Vandyck',\n",
              " 'Giustiniani',\n",
              " 'Pallavicini',\n",
              " 'Guido Reni',\n",
              " 'Rubens',\n",
              " 'Garibaldi',\n",
              " 'Pagano Doria',\n",
              " 'Luciano Doria',\n",
              " 'Oberto Doria',\n",
              " 'Filippino Doria',\n",
              " 'Andrea Morosini',\n",
              " 'Loto',\n",
              " 'Count Ugolino',\n",
              " 'Andrea',\n",
              " 'Montorsoli',\n",
              " 'Pope Paul III',\n",
              " 'Andrea Doria',\n",
              " 'Giovandrea',\n",
              " 'Galeazzo Alessi',\n",
              " 'Vandyck',\n",
              " 'Rubens',\n",
              " 'Titian',\n",
              " 'Giambattista Nani',\n",
              " 'Velasquez',\n",
              " 'John Evelyn',\n",
              " 'Simone Boccanegra',\n",
              " 'Urban V',\n",
              " 'Urban VI',\n",
              " 'Francisco Maria Balbi',\n",
              " 'Tornson',\n",
              " 'Bartolommeo Bianco',\n",
              " 'Giovanni da Bologna',\n",
              " 'Bacon',\n",
              " 'Sirus',\n",
              " 'Carlone',\n",
              " 'Paganini',\n",
              " 'Sarasate',\n",
              " 'Se√±or Sarasate',\n",
              " 'Leonardo',\n",
              " 'Spenser',\n",
              " 'Giorgione',\n",
              " 'Della Porta',\n",
              " 'Rocco Lurago',\n",
              " 'Franco Lercaro',\n",
              " 'Alessandro Farnese',\n",
              " 'James I of England',\n",
              " 'Philip IV of Spain',\n",
              " 'Philip II of Spain',\n",
              " 'Francesco Maria Balbi',\n",
              " 'Justi',\n",
              " 'Le Mesurier',\n",
              " 'Shelley',\n",
              " 'Mary',\n",
              " 'Claire',\n",
              " 'Trelawney',\n",
              " 'Williams',\n",
              " 'Byron',\n",
              " 'Charles V',\n",
              " 'Francis I',\n",
              " 'Jesus',\n",
              " 'Petrarch',\n",
              " 'Guido',\n",
              " 'S. Margherita',\n",
              " 'Claire',\n",
              " 'Shelley',\n",
              " 'Williams',\n",
              " 'Trelawney',\n",
              " 'Leigh Hunt',\n",
              " 'Vincent Eyre',\n",
              " 'Dr. Garnett',\n",
              " 'Professor Dowden',\n",
              " 'Byron',\n",
              " 'Eyre',\n",
              " 'Aeschylus',\n",
              " 'Keats',\n",
              " 'Tommaso Parentucelli',\n",
              " 'Vespasiano da Bisticci',\n",
              " \"Cosimo de' Medici\",\n",
              " 'Rinaldo degli Albizzi',\n",
              " 'Palla Strozzi',\n",
              " 'Filelfo',\n",
              " 'Manetti',\n",
              " 'Tomaso da Serezano',\n",
              " 'Pope Nicholas V',\n",
              " 'Vespasiano',\n",
              " 'Messer Rinaldo degli Albizzi',\n",
              " 'Messer Palla di Nofri Strozzi',\n",
              " 'Pius II',\n",
              " 'Sigismondo Malatesta',\n",
              " 'Virgil',\n",
              " 'Cassandra']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultado_final[\"person\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbS-LsFwYxKa"
      },
      "source": [
        "#### Save results to a DataFrame\n",
        "\n",
        "If we're satisfied with the results, we can eventually save them to a Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5hD6esoYz06"
      },
      "outputs": [],
      "source": [
        "path = \"./CLSinfra/\"\n",
        "for key, values in final_result.items():\n",
        "    # Convert value lists to DataFrame\n",
        "    df = pd.DataFrame(values, columns=[key])\n",
        "    # Save as .CSV-file\n",
        "    filename = f\"{key}.csv\"  \n",
        "    df.to_csv(path+filename, index=False)\n",
        "    print(f\"Archivo guardado: {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5.- EXAMPLE for loading  data to a dataframe üìú\n",
        "\n",
        "In this code snippet we collect a multilingual corpus of travel literature from the GitHub repository pertaining to GhentCDH. You can find more information on this example corpus on our [GitHub repository](https://github.com/GhentCDH/CLSinfra).\n",
        "\n",
        "To show you how this workflow can work for different languages, we'll load in our **Dutch** and **English** annotations. We annotated two aspects in these texts: **fauna** üê± and **flora** üå∫. These include common names and scientific denominations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load in our example texts\n",
        "!git clone https://github.com/GhentCDH/CLSinfra.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"./CLSinfra/Example_data_CLS/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./CLSinfra/Example_data_CLS/Dutch/haan098besc02_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/blin001verz01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/have010vree01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/piet077omst01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/gerr049besc01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/oltm003vade01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/have010door01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/haff003reiz01_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/haff003lotg02_01.txt\n",
            "./CLSinfra/Example_data_CLS/Dutch/woen003aant01_01.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1207.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1213.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1210.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP938.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1062.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1044.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1179.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP934.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP1027.txt\n",
            "./CLSinfra/Example_data_CLS/German/TP930.txt\n",
            "./CLSinfra/Example_data_CLS/English/Rome.txt\n",
            "./CLSinfra/Example_data_CLS/English/Florence_and_Northern_Tuscany_with_Genoa.txt\n",
            "./CLSinfra/Example_data_CLS/English/Cathedral_Cities_of_Italy.txt\n",
            "./CLSinfra/Example_data_CLS/English/A_Wanderer_in_Florence.txt\n",
            "./CLSinfra/Example_data_CLS/English/A_Wanderer_in_Venice.txt\n",
            "./CLSinfra/Example_data_CLS/English/Venice.txt\n",
            "./CLSinfra/Example_data_CLS/English/Roman_Holidays_and_Others.txt\n",
            "./CLSinfra/Example_data_CLS/English/Italian_Highways_and_Byways_from_a_Motor_Car.txt\n",
            "./CLSinfra/Example_data_CLS/English/Studies_of_Travel_Italy.txt\n",
            "./CLSinfra/Example_data_CLS/English/Vistas_in_Sicily.txt\n",
            "./CLSinfra/Example_data_CLS/French/46469-0.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg22575.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg23047.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg15556.txt\n",
            "./CLSinfra/Example_data_CLS/French/14163-0.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg15434.txt\n",
            "./CLSinfra/Example_data_CLS/French/58063-0.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg67080.txt\n",
            "./CLSinfra/Example_data_CLS/French/46870-0.txt\n",
            "./CLSinfra/Example_data_CLS/French/pg38242.txt\n"
          ]
        }
      ],
      "source": [
        "all_travelogues = []\n",
        "\n",
        "for filename in glob.glob(f\"{path}*/*.txt\"):\n",
        "  print(filename)\n",
        "\n",
        "  name_file = os.path.basename(filename) #find filename\n",
        "  folder_name = os.path.dirname(filename).split(\"/\")[-1] #find folder name (in our case: the language)\n",
        "\n",
        "  with open(filename, \"r\") as travelogue:\n",
        "\n",
        "    text = travelogue.read()\n",
        "    travelogue_data = {\"file\": name_file, \"text\": text, \"language\": folder_name}\n",
        "    all_travelogues.append(travelogue_data)\n",
        "\n",
        "travel_df = pd.DataFrame(all_travelogues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Make separate corpora per language\n",
        "English_corpus = travel_df[travel_df[\"language\"] == \"English\"]\n",
        "Dutch_corpus = travel_df[travel_df[\"language\"] == \"Dutch\"]\n",
        "German_corpus = travel_df[travel_df[\"language\"] == \"German\"]\n",
        "French_corpus = travel_df[travel_df[\"language\"] == \"French\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "EN_fauna_flora = pd.read_csv(\"./CLSinfra/Example_data_CLS/EN_fauna_flora_df.csv\")\n",
        "NL_fauna_flora = pd.read_csv(\"./CLSinfra/Example_data_CLS/NL_fauna_flora_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>text</th>\n",
              "      <th>_sentence_text</th>\n",
              "      <th>aspect_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>BHL_957_sample_Dutch_19.0.txt_15419-15433</td>\n",
              "      <td>Hirundo</td>\n",
              "      <td>P. ) Hirundo ?</td>\n",
              "      <td>FAUNA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>BHL_794_sample_Dutch_18.0.txt_1106-1417</td>\n",
              "      <td>bladeren</td>\n",
              "      <td>Men wirt hier de bladeren van 't geboomte niet...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>BHL_7_sample_Dutch_19.0.txt_1946-2236</td>\n",
              "      <td>obtusipetalus</td>\n",
              "      <td>Onder de soorten met twee ( zelden √©√©n ) midde...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DBNL-151_sample_IAA_19.txt_1626-1841</td>\n",
              "      <td>kaaiman</td>\n",
              "      <td>Op onze vaart daarheen hadden wij nog het voor...</td>\n",
              "      <td>FAUNA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>BHL_794_sample_Dutch_18.0.txt_940-1003</td>\n",
              "      <td>vee</td>\n",
              "      <td>Men zait maar wei- nig garft , en dat nog alle...</td>\n",
              "      <td>FAUNA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>DBNL-10_sample20 (1).txt_9491-9642</td>\n",
              "      <td>hout</td>\n",
              "      <td>De Corso is een gedeelte van de boulevard , zo...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>BHL_7_sample_Dutch_19.0.txt_13264-13333</td>\n",
              "      <td>knobbels</td>\n",
              "      <td>Die knobbels zijn dicht opeengedrongen en spir...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>BHL_7_sample_Dutch_19.0.txt_443-642</td>\n",
              "      <td>randdorens</td>\n",
              "      <td>Indien zij verschillen , kunnen de middendoren...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>BHL_957_sample_Dutch_19.0.txt_13870-13879</td>\n",
              "      <td>Canis</td>\n",
              "      <td>Canis ‚Äî ?</td>\n",
              "      <td>FAUNA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>BHL_7_sample_Dutch_19.0.txt_4330-4440</td>\n",
              "      <td>M. communis</td>\n",
              "      <td>Alleen merkt hij op , dat onder den naam van M...</td>\n",
              "      <td>FLORA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      sentence           text  \\\n",
              "133  BHL_957_sample_Dutch_19.0.txt_15419-15433        Hirundo   \n",
              "239    BHL_794_sample_Dutch_18.0.txt_1106-1417       bladeren   \n",
              "387      BHL_7_sample_Dutch_19.0.txt_1946-2236  obtusipetalus   \n",
              "3         DBNL-151_sample_IAA_19.txt_1626-1841        kaaiman   \n",
              "234     BHL_794_sample_Dutch_18.0.txt_940-1003            vee   \n",
              "550         DBNL-10_sample20 (1).txt_9491-9642           hout   \n",
              "448    BHL_7_sample_Dutch_19.0.txt_13264-13333       knobbels   \n",
              "377        BHL_7_sample_Dutch_19.0.txt_443-642     randdorens   \n",
              "101  BHL_957_sample_Dutch_19.0.txt_13870-13879          Canis   \n",
              "413      BHL_7_sample_Dutch_19.0.txt_4330-4440    M. communis   \n",
              "\n",
              "                                        _sentence_text aspect_cat  \n",
              "133                                     P. ) Hirundo ?      FAUNA  \n",
              "239  Men wirt hier de bladeren van 't geboomte niet...      FLORA  \n",
              "387  Onder de soorten met twee ( zelden √©√©n ) midde...      FLORA  \n",
              "3    Op onze vaart daarheen hadden wij nog het voor...      FAUNA  \n",
              "234  Men zait maar wei- nig garft , en dat nog alle...      FAUNA  \n",
              "550  De Corso is een gedeelte van de boulevard , zo...      FLORA  \n",
              "448  Die knobbels zijn dicht opeengedrongen en spir...      FLORA  \n",
              "377  Indien zij verschillen , kunnen de middendoren...      FLORA  \n",
              "101                                          Canis ‚Äî ?      FAUNA  \n",
              "413  Alleen merkt hij op , dat onder den naam van M...      FLORA  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NL_fauna_flora.sample(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QJZ2qVpCzIoB",
        "c8xbS61Zz1SH",
        "fyGlgl8OzIoM",
        "1McPbxhD-uab",
        "0qX312StFXwx",
        "OLVxG9VszIoN",
        "UGJkItJGPIGx",
        "32WstRkNPnCs",
        "Dn0uQx45XkCx",
        "gbS-LsFwYxKa",
        "Kb1c2_dpDino",
        "6kkq-38lhZdR"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
