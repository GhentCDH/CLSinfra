{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-6LcNytfRxt",
        "outputId": "67ef561e-ef6e-481b-cb56-3d5c5ddbe824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: /usr/local/bin/pip: bad interpreter: /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python: no such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "!pip3 install numpy\n",
        "!pip3 install scipy\n",
        "!pip install statsmodels\n",
        "!pip3 install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpLQidfPfRxx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nervaluate\n",
        "import ast\n",
        "from nervaluate import Evaluator\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUwAQa2hfRxz"
      },
      "source": [
        "# Contrast Analysis\n",
        "\n",
        "This Notebook provides code to find significant differences in model performance across groups (e.g.: in our case, we used it to calculate the performance of prompts across centuries and entity category labels.).\n",
        "\n",
        "Normality Test: Uses the Shapiro-Wilk test to assess whether the data for each metric is normally distributed within each group.\n",
        "ANOVA Test: If all groups are normal, performs a one-way ANOVA to check for significant differences between group means.\n",
        "Post Hoc Analysis: If ANOVA finds significant differences, performs Tukey's test for pairwise comparisons.\n",
        "Non-parametric Test: If the normality assumption fails, uses the Kruskal-Wallis test to detect differences between groups.\n",
        "Post Hoc for Non-parametric Data: If Kruskal-Wallis finds significant differences, performs pairwise Mann-Whitney U tests.\n",
        "\n",
        "The Notebook creates a results file summarizing normality tests, ANOVA/Kruskal-Wallis tests, and post hoc comparisons for the dataset at hand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j_SuzxbfRx1"
      },
      "outputs": [],
      "source": [
        "# This code built a dataframe with  with all the information compute in the 4 different scenarios: strict,exact,type and partial for the three metrics: precision, recall and F1 For the general case include all the tags in a sentence and for the different tags in each sentence. Make a contrst analysis grouping by kind of prompt and century for all the samples and for the samples order by categories. All the distributions are not normal.\n",
        "\n",
        "values=['chain_of_thought_FS',\n",
        "'chain_of_thought',\n",
        "'few_shot',\n",
        "'one_shot']\n",
        "\n",
        "#Person, hay que sumar uno al indice de la izauierda y al de la derecha en la siguiente celda\n",
        "ranges={ 'GENERAL':[11,23],\n",
        "        'PERSON':[23,36],\n",
        "        'LOCATION':[36,49],\n",
        "        'FAUNA':[49,62],\n",
        "        'FLORA':[62,75],\n",
        "        'WEATHER':[75,88],\n",
        "        'ORGANISATION':[88,101],\n",
        "        'BIOME':[101,114],\n",
        "        'MYTH':[114,127],\n",
        "        'HUM_LANDFORM':[127,140],\n",
        "        'NAT_LANDFORM':[140,153],\n",
        "        'NAT_PHENOMENON':[153,166],\n",
        "        'LAND_COVER':[166,179],\n",
        "        }\n",
        "tags=['PERSON', 'LOCATION','FAUNA','FLORA', 'WEATHER', 'ORGANISATION','BIOME','MYTH','HUM_LANDFORM','NAT_LANDFORM','NAT_PHENOMENON','LAND_COVER']\n",
        "# Field for grouping in the contrast analysis. Prompt to analyze based on the type of prompt, Century  to analyze based on the Century :-)\n",
        "prompt=['prompt','Century']\n",
        "\n",
        "# Build a dataframe with all the information compute in the 4 different scenarios: strict,exact,type and partial for the three metrics: precision, recall and F1 For the general case include all the tags in a sentence and for the different tags in each sentence.\n",
        "\n",
        "analyze=pd.DataFrame()\n",
        "result=[]\n",
        "path='/Users/salvador/GitHub/absa-travelogues/ABSA_data_ok/resultado_ok_century/'\n",
        "for value in values:\n",
        "    es_ok=pd.read_csv(path+f'TODO_normalizado_{valor}_english_fin_ok.csv')\n",
        "    es_ok['prompt']=value\n",
        "    result.append(es_ok)\n",
        "    analyze = pd.concat(result, ignore_index=True)\n",
        "\n",
        "for group in prompt:\n",
        "        for key,lista in rangos.items():\n",
        "                if key!='GENERAL':\n",
        "                        analiza_1=analyze[analyze[analyze.columns[lista[0]]]==key]\n",
        "                        lista_columnas=df.columns[lista[0]+1:lista[1]]\n",
        "                else:\n",
        "                        analiza_1=analyze\n",
        "                        lista_columnas=df.columns[lista[0]:lista[1]]\n",
        "                contrast_analysis(analiza_1,group,key,path,list_columnas=lista_columnas)\n",
        "\n",
        "#pinta_violin(analiza,campo='Recall_strict',grupo='prompt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVwWTid5fRx3"
      },
      "outputs": [],
      "source": [
        "# This code performs contrast analysis grouped by the group variable.\n",
        "# analyze is the dataframe to analyze and should contain the values of different metrics as well as the grouping variable if necessary.\n",
        "\n",
        "def contrast_analysis(analyze, group_var, key, path, column_list):\n",
        "    # group_var='prompt'\n",
        "    # group_var='Century'\n",
        "    # analyze.columns[12:24];\n",
        "    columns = column_list\n",
        "    # Filter the data for the different metrics\n",
        "    # Check the normality of each group\n",
        "    file = path + f'result_{key}_{group_var}'\n",
        "    with open(file, \"w\") as file:\n",
        "        count_samples = analyze.shape[0]\n",
        "        # Display the result\n",
        "        screen = f'Number of {key} samples are {count_samples}\\n\\n'\n",
        "        file.write(screen)\n",
        "        for value in columns:\n",
        "            group_normality = analyze.groupby(group_var)[value].apply(lambda x: stats.shapiro(x)[1])\n",
        "            screen = f\"Normality test by group={group_var} for {value}\\n\"\n",
        "            print(screen)\n",
        "            print(group_normality)\n",
        "            file.write(screen)\n",
        "            file.write(str(group_normality))\n",
        "\n",
        "            # Check if the data is normal in general and by group\n",
        "            if group_normality.min() > 0.05:\n",
        "                screen = \"The data is normal in all groups. ANOVA can be performed.\"\n",
        "                print(screen)\n",
        "                file.write(screen)\n",
        "                # Remove groups with less than 2 observations and null data\n",
        "                stat, p_value = stats.f_oneway(\n",
        "                    *[group[value].values for _, group in analyze.groupby(group_var)]\n",
        "                )\n",
        "\n",
        "                screen = f\"ANOVA for {value}: p-value = {p_value}\\n\"\n",
        "                print(screen)\n",
        "                file.write(screen)\n",
        "\n",
        "                if p_value < 0.05:\n",
        "                    screen = \"Significant results. Performing Tukey post hoc test...\\n\"\n",
        "                    print(screen)\n",
        "                    file.write(screen)\n",
        "                    tukey = pairwise_tukeyhsd(endog=analyze[value], groups=analyze[group_var], alpha=0.05)\n",
        "                    screen = \"Post Hoc Test (Tukey):\\n\"\n",
        "                    print(screen)\n",
        "                    print(tukey.summary())\n",
        "                    file.write(screen)\n",
        "                    file.write(str(tukey.summary()))\n",
        "\n",
        "                else:\n",
        "                    screen = f\"No significant differences between the {group_var} groups for the {value} index.\"\n",
        "                    print(screen)\n",
        "                    file.write(screen)\n",
        "            else:\n",
        "                screen = \"The data is not normal in all groups. It is recommended to perform a non-parametric test such as Kruskal-Wallis.\\n\"\n",
        "                print(screen)\n",
        "                file.write(screen)\n",
        "                stat, p_value = stats.kruskal(\n",
        "                    *[group[value].values for _, group in analyze.groupby(group_var)]\n",
        "                )\n",
        "                screen = f\"Kruskal-Wallis for {value}: p-value = {p_value}\\n\\n\"\n",
        "                print(screen)\n",
        "                file.write(screen)\n",
        "                medians = analyze.groupby(group_var)[value].median()\n",
        "                means = analyze.groupby(group_var)[value].mean()\n",
        "                screen = f'Medians={medians}\\n'\n",
        "                file.write(screen)\n",
        "                screen = f'Means={means}\\n'\n",
        "                file.write(screen)\n",
        "                print('Means', means)\n",
        "                if p_value <= 0.05:\n",
        "                    screen = \"There are significant differences. Performing pairwise post hoc analysis (Mann-Whitney U)...\\n\"\n",
        "                    print(screen)\n",
        "                    file.write(screen)\n",
        "                    group_names = analyze[group_var].unique()\n",
        "                    for i in range(len(group_names)):\n",
        "                        for j in range(i + 1, len(group_names)):\n",
        "                            group1 = analyze[analyze[group_var] == group_names[i]][value]\n",
        "                            group2 = analyze[analyze[group_var] == group_names[j]][value]\n",
        "                            stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
        "\n",
        "                            screen = (f\"Comparison {group_names[i]} vs {group_names[j]}: p-value = {p_value}, : Stat, {stat}\\n\")\n",
        "                            print(screen)\n",
        "                            file.write(screen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXcAd8T9fRx5"
      },
      "outputs": [],
      "source": [
        "def pinta_violin (analiza,campo,grupo):\n",
        "    outliers = analiza[analiza[campo] > 1]\n",
        "    if outliers.empty:\n",
        "        print(f\"There are no values greater than 1:\\n\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.violinplot(\n",
        "        data=analyze,\n",
        "        x=grupo,\n",
        "        y=campo,\n",
        "        hue=grupo,  # Asigna `Century` a `hue` para que la paleta funcione correctamente\n",
        "        palette=\"Set2\",\n",
        "        linewidth=2,\n",
        "        #inner=\"quartile\",\n",
        "        dodge=False,    # Evita que se separe por categorías del hue\n",
        "        legend=False    # Desactiva la leyenda\n",
        "    )\n",
        "    #sns.violinplot(x='Century', y='PERSON_strict_F1', data=persona, palette='muted', inner='quartile')\n",
        "    medianas = analiza.groupby(grupo)[campo].median()\n",
        "    medias= analiza.groupby(grupo)[campo].mean()\n",
        "    print('Medianas',medianas)\n",
        "    print('Medias',medias)\n",
        "    for i, median in enumerate(medianas):\n",
        "        plt.scatter(i, median, color=\"red\", s=50, zorder=5, label=\"Median\" if i == 0 else \"\")\n",
        "    for i, media in enumerate(medias):\n",
        "        plt.scatter(i, media, color=\"blue\", s=50, zorder=5, label=\"Media\" if i == 0 else \"\")\n",
        "\n",
        "    # Personalizar el gráfico\n",
        "    #plt.legend(loc=\"upper left\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('Group Distribution', fontsize=14)\n",
        "    plt.xlabel(grupo, fontsize=12)\n",
        "    plt.ylabel(campo, fontsize=12)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neurips-llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}